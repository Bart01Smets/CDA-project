---
title: "Analysis of Continuous Data project"
author: "Thomas Sertijn, Bart Smets, Ilja Van Bever, Lieselot Van de Putte"
date: "2025-11-09"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(message = FALSE, warning = FALSE,
                      echo = TRUE)
```

# Protocol - Univariate part

```{r echo=FALSE}
library(knitr)
library (glue)
library(dplyr)
```

## Research question

During this research, we want to investigate how socio-economic disadvantage relates to violent crime rates. More specifically we want to explore the association between poverty and violent crime rates in the USA.

In his seminal work, Becker (1968) stated that the decision to commit crime is a rational choice where people weigh the benefits and costs against each other. It could then be argued that the incentive to commit crime is higher for people who have a lower income, as the benefits are larger for this group. Following this, we would then also expect that in communities with a higher poverty rate, there will also be higher crime rates. Depending on the results of our analysis, these results could be used to inform relevant policies. It would, for example, give another argument for the implementation of redistributive policies: if an effect is found, policymakers should take this reduction in violent crime into account, next to an economic benefit. Our analysis hopes to shed further light on this issue.

For the purpose of our research question, the following predictor variables have been selected:

-   **PctPopUnderPov**: percentage of people under the poverty level (main predictor).
-   **perCapInc**: per capita income. While similar to pctunderpoverty, this takes the whole income distribution into account and not just the lower end. If this average is lower, then we expect more crime to happen.
-   **PctEmploy**: percentage of people 16 and over who are employed. We could argue that if more people are employed less people have an incentive to commit crime.
-   **PctLess9thGrade**: percentage of people 25 and over with less than a 9th grade education. Education leads to a higher socio-economic standing, which would suggest that people have less reason to commit crime. We choose this variable for now, but as an alternative we could later use one of the following two variables if we would find them better suited as predictors: **PctNotHSGrad** (percentage of people 25 or over, that have not graduated highschool) or **PctBSorMore** (percentage of people 25 or over, with at least a bachelor's degree).
-   **NumImmig**: total number of people known to be foreign born. Immigrants commiting more crimes is a commonly used right-wing argument against migration, and relevant as immigrants are often from a 'lower' socio-economic background.
-   **racepctblac**: percentage of population that is african american. It is a common right wing argument as well that black people commit crime, because they are from a 'lower' socio-economic background.
-   **agePct12t29**: percentage of population that is 12-29 in age. We include this because young people have had less time to build up their socio-economic status, as well as their brain being less developed, and might thus commit more crime.

## Design of the study


## Descriptive analysis

To get a first impression of the data, a descriptive analysis will be performed for the candidate predictor variables (all continuous). The datasets are checked for missing values. The most common univariate statistics are calculated: the mean, the standard deviation, the minimum, the first quartile, the median, the third quartile and the maximum.

The distributions of the variables are visualized by boxplots, QQ plots and histograms. Outliers are identified using Tukey’s 1.5 x IQR rule. For the univariate descriptive statistics also the population size of the communities is considered. The population size can influence the reliability of the data points: small communities can have a higher probability to have more extreme values of the predictor and response variables by the fact that the denominator in the response variable (total number of violent crimes per 100K population) is smaller. In the regression phase this will be used to investigate the outlier values.

To find what the relationship is between the main predictor variable and the potential extra predictor variables, scatter plots with smoothers are made for the bivariate relationships and correlations are checked.

## Linear regression

Before performing linear regression and building models, the dataset is split into a training set (80% of the data) and a test set (20% of the data).

To investigate the association between the main predictor variable and the response variable, a linear regression is fitted and the output is evaluated. The various statistics are calculated and discussed: estimate regression coefficients, the F-statistics (/t-statistics), the R squared, the MSE, the p-value, the confidence interval and standard error of the slope. We first present the general formula here, before we fill in the specific variables.

$$
Y_i = \beta_0 + \beta_1X_i + \epsilon_i 
$$

$$
ViolentCrimesPerPop_i = \beta_0 + \beta_1pctpopUnderPov_i + \epsilon_i 
$$

Confidence intervals are constructed. Based on this, outliers can be identified. Subsequently, the outliers are further evaluated, e.g. are outliers linked to communities with a small population size.

## Assumption checks

For linear regression, multiple assumptions, such as linearity, independence of errors, homoscedasticity (constant variance of errors), and normality of errors, are made. During this research these assumptions have to be checked by: Plotting residuals vs. fitted values for the linearity and independence of errors, squared residuals vs. fitted values for homoscedasticity checks, normality checks by qq-plot of the residuals. To also take leverage into account, the studentized residuals will be plotted.

# Protocol - Multivariate part

## Model building
Forward stepwise regression
Evaluation of adjusted R-squared, AIC, SBC
Partial regression plots? In which functional form we let a variable enter the model?

## Model fit and outliers
PRESS, studentized residual plots (transformations needed?), bijv. QQ-plots to predicted value of y/log(y), 
Also DFFITS, Cook's Distance, DFBETAS -> welke outliers hebben een grote invloed? Deleted residuals?

## Interpretation of the parameters


```{r echo=FALSE}
# Create the table in R
schedule <- data.frame(
  Deadline = c("3/11", "10/11", "17/11", "24/11", "24/11", "1/12", "1/12", "1/12", "8/12", "8/12", "8/12"),
  Subject = c("Data extraction",
              "Descriptive analyses",
              "Model building",
              "Model interpretation",
              "Prediction with linear model",
              "Statistical discussion linear model",
              "Fitting GLM",
              "Fitting the final model",
              "Prediction with GLM",
              "Statistical discussion GLM",
              "Final conclusion and discussion"),
  Final_responsibility = c("Thomas",
                           "Ilja",
                           "Bart",
                           "Lieselot",
                           "Ilja",
                           "Bart",
                           "Lieselot",
                           "Thomas",
                           "Ilja",
                           "Thomas",
                           "Lieselot")
)

# Print the table
kable(schedule, caption = "Project Schedule Overview", align = c('c', 'l', 'c'))
```

# Data extraction:
---- load data ----
```{r}
library(data.table)
violent_crimes_table <- fread("curl https://archive.ics.uci.edu/static/public/211/communities+and+crime+unnormalized.zip")
```
---- remotely get variable names ---- 
```{r}
library(dplyr)
library(stringr)
library(rvest)
url <- "https://archive.ics.uci.edu/dataset/211/communities+and+crime+unnormalized"

# Read the HTML page
page <- read_html(url)

# Extract all text from the page
text <- page %>% html_text()

# Split into lines
lines <- str_split(text, "\n")[[1]]

start <- grep("Additional Variable Information", lines, ignore.case = TRUE)
end   <- grep("Summary Statistics:", lines, ignore.case = TRUE)

# only retain the lines starting with --
var_lines <- lines[str_starts(str_trim(lines), "--")]
# remove the --
var_names <- sapply(strsplit(var_lines, "--"), function(x) str_trim(x[2]))
# only retain the variable names by cutting everything after the :
var_names <- str_extract(var_names, "^[^:]+")
```
----------------------------------
#remove in final product
----------------------------------
```{r}
# variable_names <- list("communityname","state","countyCode", "communityCode", "fold", "population", "householdsize", 
#                        "racepctblack", "racePctWhite", "racePctAsian", "racePctHisp", "agePct12t21", "agePct12t29", "agePct16t24",
#                        "agePct65up", "numbUrban", "pctUrban", "medIncome", "pctWWage", "pctWFarmSelf", "pctWInvInc", "pctWSocSec",
#                        "pctWPubAsst", "pctWRetire", "medFamInc", "perCapInc", "whitePerCap", "blackPerCap", "indianPerCap", "AsianPerCap", 
#                        "OtherPerCap", "HispPerCap", "NumUnderPov", "PctPopUnderPov", "PctLess9thGrade", "PctNotHSGrad", "PctBSorMore", 
#                        "PctUnemployed", "PctEmploy", "PctEmplManu", "PctEmplProfServ", "PctOccupManu", "PctOccupMgmtProf", "MalePctDivorce",
#                        "MalePctNevMarr", "FemalePctDiv", "TotalPctDiv", "PersPerFam", "PctFam2Par", "PctKids2Par", "PctYoungKids2Par", 
#                        "PctTeen2Par", "PctWorkMomYoungKids", "PctWorkMom", "NumKidsBornNeverMar", "PctKidsBornNeverMar", "NumImmig",
#                        "PctImmigRecent", "PctImmigRec5", "PctImmigRec8", "PctImmigRec10", "PctRecentImmig", "PctRecImmig5", "PctRecImmig8",
#                        "PctRecImmig10", "PctSpeakEnglOnly", "PctNotSpeakEnglWell", "PctLargHouseFam", "PctLargHouseOccup", "PersPerOccupHous",
#                        "PersPerOwnOccHous", "PersPerRentOccHous", "PctPersOwnOccup", "PctPersDenseHous", "PctHousLess3BR", "MedNumBR",
#                        "HousVacant", "PctHousOccup", "PctHousOwnOcc", "PctVacantBoarded", "PctVacMore6Mos", "MedYrHousBuilt",
#                        "PctHousNoPhone", "PctWOFullPlumb", "OwnOccLowQuart", "OwnOccMedVal", "OwnOccHiQuart", "OwnOccQrange", "RentLowQ",
#                        "RentMedian", "RentHighQ", "RentQrange", "MedRent", "MedRentPctHousInc", "MedOwnCostPctInc", "MedOwnCostPctIncNoMtg",
#                        "NumInShelters", "NumStreet", "PctForeignBorn", "PctBornSameState", "PctSameHouse85", "PctSameCity85",
#                        "PctSameState85", "LemasSwornFT", "LemasSwFTPerPop", "LemasSwFTFieldOps", "LemasSwFTFieldPerPop", "LemasTotalReq",
#                        "LemasTotReqPerPop", "PolicReqPerOffic", "PolicPerPop", "RacialMatchCommPol", "PctPolicWhite", "PctPolicBlack",
#                        "PctPolicHisp", "PctPolicAsian", "PctPolicMinor", "OfficAssgnDrugUnits", "NumKindsDrugsSeiz", "PolicAveOTWorked",
#                        "LandArea", "PopDens", "PctUsePubTrans", "PolicCars", "PolicOperBudg", "LemasPctPolicOnPatr", "LemasGangUnitDeploy",
#                        "LemasPctOfficDrugUn", "PolicBudgPerPop", "murders", "murdPerPop", "rapes", "rapesPerPop", "robberies", "robbbPerPop",
#                        "assaults", "assaultPerPop", "burglaries", "burglPerPop", "larcenies", "larcPerPop", "autoTheft", "autoTheftPerPop", 
#                        "arsons", "arsonsPerPop", "ViolentCrimesPerPop", "nonViolPerPop")
```
---------------------------------------
# end of removable part
---------------------------------------

```{r}
colnames(violent_crimes_table) <- var_names 
```

```{r}
crimes_table_subset <- violent_crimes_table %>% 
  dplyr::select(communityname,state,countyCode, communityCode, fold, population, 
         PctPopUnderPov, perCapInc, PctEmploy, PctLess9thGrade, PctNotHSGrad, PctBSorMore,
         NumImmig, racepctblack, agePct12t29, ViolentCrimesPerPop
         )
```

# Design

The dataset combines 1990 U.S. Census socio-economic data, 1990 law enforcement data from the Law Enforcement Management and Admin Stats (LEMAS) survey, and 1995 FBI crime data, thereby creating two cohorts. For the FBI crime data, it is mentioned that states with a lower amount of visitors have a lower per capita crime rate and vice verse. The LEMAS survey covers all communities with police departments of at least 100 officers and a random sample of smaller departments. If communities were absent from either the crime or census datasets (e.g., those with very small departments), then they were removed. All demographic data is from 1990, but per-capita crime rates use 1995 population counts. Finally, rape counts, a component of violent crime, are missing in some states due to inconsistent reporting, which resulted in missing total violent crime values for those states. We will investigate whether this missingness has probably a large effect on the model and if necessary use imputations.

# Data preparation

```{r, include=FALSE}
library(ggplot2)
library(gtsummary)
library(sjlabelled)
library(tidyr)
```

Since the outcome variable *ViolentCrimesPerPop* (total number of violent crimes per 100K population) is expressed relative to the population size, the variable *NumImmig* is converted (by dividing it by the population size and multiplying by 100%). It's important to mention that this is not an exact transformation, because all demographic
data is from 1990, but per-capita crime rates use 1995 population counts. 
```{r}
crimes_table_subset$ViolentCrimesPerPop <- as.numeric(crimes_table_subset$ViolentCrimesPerPop)
crimes_table_subset$PctImmig <- crimes_table_subset$NumImmig/crimes_table_subset$population*100
crimes_table_subset = crimes_table_subset[,-c('NumImmig', 'fold')]
```
```{r}
sjlabelled::set_label(crimes_table_subset) <- c("communityname", "state", "countyCode", "communityCode", "population", "people under the poverty level (%)", "per capita income ($)", "percentage of people 16 and over who are employed (%)", "percentage of people 25 and over with less than a 9th grade education (%)", "percentage of people 25
or over, that have not graduated highschool (%)", "percentage of people 25 or over, with
at least a bachelor’s degree (%)", "percentage of population that is african american (%)", "percentage of population that is 12-29 in age (%)", "total number of violent crimes per 100K population", "percentage of immigrants (%)")
```


It is examined how many NA values are present in the database.
```{r counting NA values}
crimes_table_subset %>%
  pivot_longer(cols = where(is.numeric), names_to = "variable", values_to = "value") %>%
  group_by(variable) %>%
  summarise(
    NAs = sum(is.na(value))
  )
```

The only variable for which NA values are found is the outcome variable *ViolentCrimesPerPop*. Imputations can not help a lot to handle this. As already mentioned in the section on the study design, many of these NA values are due to the fact that rape counts, a component of violent crime, were not included in the statistics for several states. The rows where the outcome variable has an NA value are removed, as these rows are not useful for the regression. It can be noted that the variables *countyCode* and *communityCode* are also frequently unknown.

```{r identifying NA values}
na_subset <- crimes_table_subset %>%
  filter(is.na(ViolentCrimesPerPop)
  )
na_subset <- na_subset[,-'ViolentCrimesPerPop']
na_subset
```


```{r}
crimes_table_subset = na.omit(crimes_table_subset)
colSums(crimes_table_subset == "?", na.rm = TRUE)
```

# Univariate descriptives

After removing NA values from the database univariate descriptives are calculated, both the missing values and the non-missing values. 

```{r summary statistics}
str(crimes_table_subset)
summary(crimes_table_subset)

crimes_table_subset %>%
  pivot_longer(cols = where(is.numeric), names_to = "variable", values_to = "value") %>%
  group_by(variable) %>%
  summarise(
    min = min(value, na.rm = TRUE),
    q25 = quantile(value, 0.25, na.rm = TRUE),
    mean = mean(value, na.rm = TRUE),
    sd = sd(value, na.rm = TRUE),
    q75 = quantile(value, 0.75, na.rm = TRUE),
    max = max(value, na.rm = TRUE),
    n = n(),
    NAs = sum(is.na(value))
  )
```
```{r summary statistics nas}
na_subset %>%
  pivot_longer(cols = where(is.numeric), names_to = "variable", values_to = "value") %>%
  group_by(variable) %>%
  summarise(
    min = min(value, na.rm = TRUE),
    q25 = quantile(value, 0.25, na.rm = TRUE),
    mean = mean(value, na.rm = TRUE),
    sd = sd(value, na.rm = TRUE),
    q75 = quantile(value, 0.75, na.rm = TRUE),
    max = max(value, na.rm = TRUE),
    n = n(),
    NAs = sum(is.na(value))
  )
```

To gain insight into the univariate distributions, boxplots and histograms are generated.

```{r boxplots, fig.width=8, fig.height=12}
numeric_cols <- sapply(crimes_table_subset, is.numeric)
crimes_table_subset_num <- crimes_table_subset[, ..numeric_cols]
par(mfrow = c(4,2))
for(columnname in names(crimes_table_subset_num)){
  column <- crimes_table_subset_num[[columnname]]
  boxplot(column,
          main = columnname
          )
  hist(column,   
       main = columnname,
       xlab = get_label(column)
          )
}
```
```{r boxplots na comparison, fig.width=8, fig.height=12, eval=FALSE, include=FALSE}
numeric_cols_na <- sapply(na_subset, is.numeric)
crimes_table_subset_num_na <- na_subset[, ..numeric_cols_na]
par(mfrow = c(4,2))
for(columnname in names(crimes_table_subset_num_na)){
  column <- crimes_table_subset_num[[columnname]]
  column_na <- crimes_table_subset_num_na[[columnname]]
  boxplot(column,
          main = columnname
          )
  boxplot(column_na,
          main = paste(columnname, "(missing data)")
          )
}
```
To investigate the impact of the missing values, the distribution of the other variables is compared in the missing data vs. the non-missing data. This is done using the histograms. Neither the summary statistics nor the scatter plots indicate that the missing data have characteristics that differ substantially from the non-missing data
```{r histograms na comparison, fig.width=8, fig.height=12}
numeric_cols_na <- sapply(na_subset, is.numeric)
crimes_table_subset_num_na <- na_subset[, ..numeric_cols_na]
par(mfrow = c(4,2))
for(columnname in names(crimes_table_subset_num_na)){
  column <- crimes_table_subset_num[[columnname]]
  column_na <- crimes_table_subset_num_na[[columnname]]
  hist(column,   
       main = columnname,
       xlab = get_label(column)
          )
  hist(column_na,   
       main = paste(columnname, "(missing data)"),
       xlab = get_label(column)
          )
}
```

# Multivariate descriptives

After investigating the univariate descriptives, multivariate descriptives are calculated.

# Multivariate descriptives

After investigating the univariate descriptives, multivariate descriptives are calculated.

The correlation matrix shows the extent to which the variables in the dataset are correlated with each other.
Below, all variables are listed, sorted from highest to lowest correlation with the outcome variable.

- *racepctblack* ($r = 0.63$)
- *PctPopUnderPov* ($r = 0.51$)
- *PctNotHSGrad* ($r = 0.47$)
- *PctLess9thGrade* ($r = 0.37$)
- *PctEmploy* ($r = -0.32$)
- *perCapInc* ($r = -0.32$)
- *PctBSorMore* ($r = 0.3$)
- *PctImmig* ($r = 0.19$)
- *agePct12t29* ($r = 0.11$)

It's important to mention that these correlations are indicators of an association, not of a causation.

The following predictors are highly correlated with each other. Therefore, it is best not to include them together in a model later.

- *PctNotHSGrad* and *PctLess9thGrade* ($r = 0.93$)
- *perCapInc* and *PctBSorMore* ($r = 0.77$)
- *PctNotHSGrad* and *PctBSorMore* ($r = -0.75$)

However the choice for predictors for the model will be dealt with thoroughly during the model building.

It is noticeable that the variable *racepctblack* is the one most strongly correlated with the outcome variable ($r = 0.63$), even more than *PctPopUnderPov*, the head predictor that was chosen for this research.

It is noticable the the variables *PctImmig* and *PctImmig* have correlation coefficients that are really low.

```{r discrib_extended, eval=FALSE, include=FALSE}
Hmisc::describe(crimes_table_subset)

```
```{r correlations}
cor_matrix <- cor(crimes_table_subset_num[,-'population'])
cor_values <- as.data.frame(as.table(cor_matrix))

library(ggcorrplot)
ggcorrplot(cor_matrix, lab = TRUE, type = "lower", 
           lab_size = 3, colors = c("red", "white", "blue"))

```
The following scatter plots were generated:

- for each variable, a scatter plot showing the relationship with the outcome variable *ViolentCrimesPerPop*;
- for each variable, a scatter plot showing the relationship with the main predictor variable *PctPopUnderPov*.

The first series of scatter plots indicates that not all variables have a linear relationship with *ViolentCrimesPerPop*.
In particular, the following variables do not appear to exhibit a clear linear trend:

- *perCapInc*
- *agePct12t29* (which also had a very low correlation coefficient)

Other variables show a somewhat linear pattern, although this trend is often distorted in the extreme regions of the x-axis.

The second series of scatter plots suggests that some variables exhibit a linear relationship with the main predictor *PctPopUnderPov*.
In particular, the following variables appear to show a fairly linear trend:

- *PctEmploy*
- *PctLess9thGrade*
- *PctNotHSGrad*

This implies that these variables are probably not suitable as additional predictors when *PctPopUnderPov* is already included in the model as this may cause multicollinearity.

```{r scatter plots, fig.width=8, fig.height=12}
x_vars <- colnames(crimes_table_subset_num)
dict_labels <- setNames(sapply(x_vars, function(x_var) get_label(crimes_table_subset_num[[x_var]])), x_vars)

library(ggplot2)
library(patchwork)
df <- crimes_table_subset_num[,-c("population")]
y_var <- "ViolentCrimesPerPop"
x_vars <- setdiff(colnames(df), y_var)
plots <- lapply(x_vars, function(x_var) {
    ggplot(df, aes_string(x_var,y_var)) +
    geom_point(alpha = 0.6, size = 0.7) +
    geom_smooth(method = "lm", color = "blue", se = FALSE)+
    geom_smooth(method = "loess", color = "red", se = FALSE)+
    theme_bw(base_size = 8) +
    labs(x = str_wrap(paste(x_var, " (", dict_labels[x_var], ")", sep = ""), width = 45))
}
)
# Print 9 plots per pg
print(wrap_plots(plots, ncol = 3))

df <- crimes_table_subset_num[,-c("population", "ViolentCrimesPerPop")]
y_var <- "PctPopUnderPov"
x_vars <- setdiff(colnames(df), y_var)
plots <- lapply(x_vars, function(x_var) {
    ggplot(df, aes_string(x_var,y_var))+
    geom_point(alpha = 0.6, size = 0.7) +
    geom_smooth(method = "lm", color = "blue", se = FALSE)+
    geom_smooth(method = "loess", color = "red", se = FALSE)+
    theme_bw(base_size = 8) +
    labs(x = str_wrap(paste(x_var, " (", dict_labels[x_var], ")", sep = ""), width = 45))
}
)

# Print 9 plots per pg
print(wrap_plots(plots, ncol = 3))
```


The scatter plots reveal one outlier for the ViolentCrimesPerPop variable. This outlier is the community Chestercity. For now the datapoint is kept for further analysis.

```{r outlier}
crimes_table_subset[order(crimes_table_subset_num$ViolentCrimesPerPop, decreasing=TRUE), , drop = FALSE]
```


In the protocol it's stated that small communities may have a higher probability to have more extreme values of the predictor and response variables. To investigate this scatter plots are created with log(*population*) as x variable. It is clear that communities with a very small population show a very large spread for all variables.

```{r scatter plots population, fig.width=8, fig.height=12}
crimes_table_subset_num$logpopulation <- lapply(crimes_table_subset_num$population, log10)
crimes_table_subset_num$logpopulation <- log10(crimes_table_subset_num$population)
df <- crimes_table_subset_num
x_var <- "logpopulation"
y_vars <- setdiff(colnames(df), x_var)
plots <- lapply(y_vars, function(y_var) {
    ggplot(df, aes_string(x_var,y_var))+
    geom_point(alpha = 0.6, size = 0.7) +
    geom_smooth(method = "lm", color = "blue", se = FALSE)+
    geom_smooth(method = "loess", color = "red", se = FALSE)+
    theme_bw(base_size = 8) +
    labs(x = "log(population)", y = str_wrap(y_var, width = 45))
}
)

# Print 9 plots per pg
print(wrap_plots(plots, ncol = 3))

```

# Model Building

Before performing linear regression and building models, the dataset is randomly split into a training set (80% of the data) and a holdout set (20% of the data). This holdout set will be used to validate the final model.

```{r dataset split}
set.seed(123)
n <- nrow(crimes_table_subset_num)
training <- sample(1:n, size = floor(0.8 * n))
train_data <- crimes_table_subset_num[training, ]
test_data <- crimes_table_subset_num[-training, ]
n_training <- nrow(train_data)

cat("Training set size:", n_training, "\n")
cat("Test set size:", nrow(test_data), "\n")
```

## Univariate linear regression

 The simple univariate regression equation we estimate with the training set is given as follows:

$$
ViolentCrimesPerPop_i = \beta_0 + \beta_1 \cdot PctPopUnderPov_i + \epsilon_i
$$

```{r Univariate regression}
fit <- lm(ViolentCrimesPerPop ~ PctPopUnderPov, data = train_data)
summary(fit)
```
We show the relevant statistics to be discussed in this section:
```{r Extract relevant statistics}

cat("Regression equation: ViolentCrimesPerPop =", 
    round(coef(fit)[1], 2), "+", 
    round(coef(fit)[2], 2), "* PctPopUnderPov\n\n")

# R-squared and BIC-value
cat("R-squared:", round(summary(fit)$r.squared, 4), "\n")
cat("Adjusted R-squared:", round(summary(fit)$adj.r.squared, 4), "\n")
cat("BIC:", BIC(fit), "\n")

# MSE
sse_simple <- sum(fit$residuals^2) 
mse_simple <- sse_simple/(n_training - 2) 
cat("SSE:", round(sse_simple, 2), "\n")
# Calculation of BIC-waarde in R: -2 * as.numeric(logLik(fit)) + attr(logLik(fit), "df") * log(n)
# Not the one from the course slides n*log(sse_simple) - n*log(n) + p*log(n), but ok?
cat("MSE:", round(mse_simple, 2), "\n")

# Confidence intervals for coefficients
cat("\n95% Confidence Intervals:\n")
print(confint(fit))

# ANOVA
anova(fit)
```

*PctPopUnderPov* = <mean> increase in violent crimes per 100K population if poverty rate increases by one percentage point

### Assumption checks

We check assumptions linearity, independence of errors, homoscedasticity, and normality of errors. It is clear these assumptions are violated. In the next step, we extend the model by adding relevant predictors and reassess the assumptions.

```{r simple-lm-diagnostics, fig.width=10, fig.height=8}
par(mfrow = c(2, 2))

#Residuals vs Fitted 
plot(fit$fitted.values, fit$residuals,
     xlab = "Fitted values", ylab = "Residuals",
     main = "Residuals vs Fitted")
abline(h = 0, col = "red", lty = 2)
lines(lowess(fit$fitted.values, fit$residuals), col = "blue")

# Squared residuals vs Fitted
plot(fit$fitted.values, fit$residuals^2,
     xlab = "Fitted values", ylab = "Squared Residuals",
     main = "Squared Residuals vs Fitted")
lines(lowess(fit$fitted.values, fit$residuals^2), col = "blue")

# QQ-plot of residuals (normality)
qqnorm(fit$residuals, main = "Normal Q-Q Plot of Residuals")
qqline(fit$residuals, col = "red")
 par(mfrow = c(1, 1))
```
Studentized residuals <dit zijn de deleted toch?> --> moet dit apart?

```{r studentized residuals}
# Studentized residuals plot
stud_res <- rstudent(fit)
plot(fit$fitted.values, stud_res,
     xlab = "Fitted values", ylab = "Studentized Residuals",
     main = "Studentized Residuals vs Fitted")
outliers_simple <- which(abs(stud_res) > 2)
```


Table to get a visual illustration of whether outliers are more common in small pop
```{r outliers vs population1}
# outliers are more present in small pop?
outlier_data <- train_data[outliers_simple, .(population, ViolentCrimesPerPop, PctPopUnderPov)]
print(outlier_data)

# Residuals vs population
plot(train_data$logpopulation, fit$residuals,
     xlab = "log(population)", ylab = "Residuals",
     main = "Residuals vs log(population)")
abline(h = 0, col = "red", lty = 2)
lines(lowess(train_data$logpopulation, fit$residuals), col = "blue")

plot(train_data$logpopulation, stud_res,
     xlab = "log(population)", ylab = "Residuals",
     main = "Studentized Residuals vs log(population)")
abline(h = 0, col = "red", lty = 2)
lines(lowess(train_data$logpopulation, stud_res), col = "blue")

```

## Model selection

We use an all-possible regressions procedure to select predictor variables. We include models with a maximum of 5 predictor variables and only models with 0, 1, or 2 education predictor variables. The best model is chosen based on the Bayesian Information Criterion.

```{r model selection, message=FALSE}

max_extra_predictors <- 4
# Define predictor variables for model selection
predictors <- c("perCapInc", "PctEmploy", 
                "PctLess9thGrade", "PctNotHSGrad", "PctBSorMore",
                "racepctblack", "agePct12t29", "PctImmig")

# Educ variables
educ <- c("PctLess9thGrade", "PctNotHSGrad", "PctBSorMore")

formulas <- list()
for (i in 1:max_extra_predictors) {
  tmp <- combn(predictors, i)
  tmp <- apply(tmp, 2, paste, collapse=" + ")
  tmp <- paste0("ViolentCrimesPerPop~PctPopUnderPov + ", tmp)
  formulas[[i]] <- tmp
}
formulas <- unlist(formulas)
formulas <- sapply(formulas, as.formula)
models <- lapply(formulas, lm, data=train_data)

bics <- sapply(models, BIC)
r_square <- sapply(models, function(m) summary(m)$r.squared)
adj_r_square <- sapply(models, function(m) summary(m)$adj.r.squared)
formula_vector <- vapply(formulas, function(f) paste(deparse(f), collapse = ""), character(1))

# build the frame
model_ranking <- data.frame(
  formula = formula_vector,
  r.square = r_square,
  adj.r.square = adj_r_square,
  BIC = bics
)
model_ranking <- model_ranking[order(model_ranking$BIC), ]
head(model_ranking, 10)
```

We then run the multivariate regression equation

```{r show best model}
# Print best model
best <- which.min(model_ranking$BIC)
best_pred <- model_ranking$formula[best]
cat("\nBest model:\n")
cat(best_pred, "\n")
cat("BIC:", round(model_ranking$BIC[best], 2), "\n")
cat("Adjusted R²:", round(model_ranking$adj.r.square[best], 4), "\n")

fit_multi <- lm(best_pred, data = train_data)
multi_var_summary <- summary(fit_multi)
multi_var_summary
```

### Partial Regression Plots

```{r partial-regression-plots, fig.width=10, fig.height=8}
predictor_list <- row.names(multi_var_summary$coefficients[-1,])

partial_regression_plot <- function(data, outcome, predictor, predictor_list) {
  temp <- train_data
  controls <- setdiff(predictor_list, predictor)
  
  formula_outcome  <- as.formula(paste(outcome, "~", paste(controls, collapse = " + ")))
  formula_pred <- as.formula(paste(predictor, "~", paste(controls, collapse = " + ")))
  
  lm_outcome <- lm(formula_outcome, data = temp)
  temp$resid_outcome <- resid(lm_outcome)
  lm_pred <- lm(formula_pred, data = temp)
  temp$resid_pred <- resid(lm_pred)

ggplot(temp, aes(x = resid_pred, y = resid_outcome)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  geom_smooth(method = "loess", se = FALSE) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  labs(x = paste("Residuals ", predictor, " ~ controls", sep = ""), y = paste("Residuals ", outcome, " ~ controls", sep = ""))
}

plots <- lapply(predictor_list, function(predictor) {
    partial_regression_plot(train_data, "ViolentCrimesPerPop", predictor, predictor_list)
}
)

# Print 9 plots per pg
print(wrap_plots(plots, ncol = 3))

```

### Interaction Terms Selection

Following the protocol, we add all interaction terms of the predictor variables with our main predictor variable *PctPopUnderPov* and evaluate their significance. We choose the best one. -> in ons protocol staat 1 of meer en hier zijn meerdere significant?

```{r interaction term selection 1}
selected_vars <- row.names(multi_var_summary$coefficients[-(1:2),])
interaction_terms <- paste("PctPopUnderPov", selected_vars, sep = ":")
 
formulas <- sapply(interaction_terms, function(i) {
  paste0(best_pred, " + ", i)
})

formulas <- lapply(formulas, as.formula)
models <- lapply(formulas, lm, data=train_data)

interaction_models_form <- vapply(formulas, function(f) 
  paste(deparse(f), collapse = ""), character(1))
summary_val_extraction <- function(x, item) {
  tmp <- summary(x)$coefficients
  tmp[nrow(tmp), item]
}
p_vals_interaction <- sapply(models, function(m) 
  summary_val_extraction(m, "Pr(>|t|)"))
t_vals_interaction <- sapply(models, function(m) 
  summary_val_extraction(m, "t value"))

bics <- sapply(models, BIC)
r_square <- sapply(models, function(m) summary(m)$r.squared)
adj_r_square <- sapply(models, function(m) summary(m)$adj.r.squared)
delta_adj_r_square <- sapply(models, function(m) 
  summary(m)$adj.r.squared - summary(fit_multi)$adj.r.squared)

interaction_table <- data.frame(
  p.vals = p_vals_interaction,
  t.vals = t_vals_interaction,
  r.square = r_square,
  adj.r.square = adj_r_square,
  delta.adj = delta_adj_r_square,
  BIC = bics
)
interaction_table <- interaction_table[order(interaction_table$p.vals), ]
interaction_table
  
best_interaction <- row.names(interaction_table[1,])
```

## Multivariate Model

Based on the model selection procedure, we fit the multivariate model including the selected interaction term.

```{r final model}
# Estimate model with interaction
formula_final <- as.formula(paste(best_pred, "+", best_interaction))

fit_final <- lm(formula_final, data = train_data)
summary(fit_final)

# confint
print(confint(fit_final))
```

### Multicollinearity Check

Before checking model assumptions, we first assess multicollinearity using the Variance Inflation Factor (VIF) and remove a variable if necessary.
```{r multicoll check}
library(car)
vif <- vif(fit_final)
print(vif)
```

As already mentioned in the section on descriptives there is multicollinearity, as PctNotHSGrad and PctLess9thGrade are highly correlated. Thus, we remove the variable with the highest VIF (PctLess9thGrade). We then do our model evaluation again, and find that the most relevant interaction term to include is now PctPopUnderPov*PctLess9thGrade

```{r address multicollinearity}
# Highest vif variable
main_effects_vif <- vif[!grepl(":", names(vif))]
highest_vif_var <- names(which.max(main_effects_vif))

# remove 
best_predictors_reduced <- setdiff(predictor_list, highest_vif_var)

# Re-evaluate interaction terms without the removed variable
other_predictors_reduced <- setdiff(best_predictors_reduced, "PctPopUnderPov")
interaction_terms_reduced <- paste("PctPopUnderPov", other_predictors_reduced, sep = ":")

interaction_results_reduced <- data.frame(
  interaction = interaction_terms_reduced,
  t_value = NA,
  p_value = NA
)

for(i in seq_along(interaction_terms_reduced)) {
  formula_int <- as.formula(paste("ViolentCrimesPerPop ~", 
                                  paste(best_predictors_reduced, collapse = " + "), "+",
                                  interaction_terms_reduced[i]))
  fit_int <- lm(formula_int, data = train_data)
  coef_summary <- summary(fit_int)$coefficients
  int_row <- nrow(coef_summary)
  interaction_results_reduced$t_value[i] <- coef_summary[int_row, "t value"]
  interaction_results_reduced$p_value[i] <- coef_summary[int_row, "Pr(>|t|)"]
}

interaction_results_reduced <- interaction_results_reduced[order(interaction_results_reduced$p_value), ]
cat("Interaction terms ranked by p-value:\n")
print(interaction_results_reduced)

best_interaction_reduced <- interaction_results_reduced$interaction[1]
cat("\nSelected interaction term:", best_interaction_reduced, "\n")

# fit reduced model
formula_final_reduced <- as.formula(paste("ViolentCrimesPerPop ~", 
                                          paste(best_predictors_reduced, collapse = " + "), "+",
                                          best_interaction_reduced))

fit_final_reduced <- lm(formula_final_reduced, data = train_data)
summary(fit_final_reduced)

cat("\n95% Confidence Intervals:\n")
print(confint(fit_final_reduced))
```

```{r vif check again}
# check vif again-->Correct
vif_adapted <- vif(fit_final_reduced)
print(vif_adapted)
```
We see that our model performs only a little less well, but this way we did account for multicollinearity and our estimates are correct.

```{r compare}
# Compare models
cat("Comparison of models:\n")
cat("Original model adjusted R²: ", round(summary(fit_multi)$adj.r.squared, 4), "\n")
cat("Reduced model adjusted R²:  ", round(summary(fit_final_reduced)$adj.r.squared, 4), "\n")

# Update fit_final 
fit_final <- fit_final_reduced
formula_final <- formula_final_reduced
best_predictors <- best_predictors_reduced
```

### Assumption checks final model

```{r final model-diagnostics, fig.width=10, fig.height=8}
par(mfrow = c(2, 2))

#Residuals vs Fitted
plot(fit_final$fitted.values, fit_final$residuals,
     xlab = "Fitted values", ylab = "Residuals",
     main = "Residuals vs Fitted (Final Model)")
abline(h = 0, col = "red", lty = 2)
lines(lowess(fit_final$fitted.values, fit_final$residuals), col = "blue")

# Squared residuals vs Fitted
plot(fit_final$fitted.values, fit_final$residuals^2,
     xlab = "Fitted values", ylab = "Squared Residuals",
     main = "Squared Residuals vs Fitted")
lines(lowess(fit_final$fitted.values, fit_final$residuals^2), col = "blue")

# QQ-plot
qqnorm(fit_final$residuals, main = "Normal Q-Q Plot (Final Model)")
qqline(fit_final$residuals, col = "red")

par(mfrow = c(1, 1))
```

## Transformation of Y
We see that the assumptions of normality and equal error variances of the error terms are again violated in the original multivariate model. A possible solution is to apply a log transformation of Y. The result shows approximate constant variances and residuals reasonably close to normal, applying the log transformation therefore offers a substantial improvement of our model. The reduction in R-squared suggests that the model-fit was inflated due to heteroscedasticity.  We still see slightly heavy tails. 

```{r}
fit_log <- lm(log(ViolentCrimesPerPop + 1) ~ 
                PctPopUnderPov + PctBSorMore + racepctblack + 
                PctImmig + PctPopUnderPov:PctBSorMore,
              data = train_data)

summary(fit_log)
plot(fit_log)
par(mfrow = c(1, 1))
```
## Rerun selection
We will repeat the model building process with the log-transformed ViolentCrimesPerPop.

```{r adding column with log transform}
train_data$logViolent <- log(train_data$ViolentCrimesPerPop + 1)
```

## Model selection

We use an all-possible regressions procedure to select predictor variables. We include models with a maximum of 5 predictor variables and only models with 0, 1, or 2 education predictor variables. The best model is chosen based on the Bayesian Information Criterion.

```{r model selection2, message=FALSE}

max_extra_predictors <- 4
# Define predictor variables for model selection
predictors <- c("perCapInc", "PctEmploy", 
                "PctLess9thGrade", "PctNotHSGrad", "PctBSorMore",
                "racepctblack", "agePct12t29", "PctImmig")

# Educ variables
educ <- c("PctLess9thGrade", "PctNotHSGrad", "PctBSorMore")

formulas <- list()
for (i in 1:max_extra_predictors) {
  tmp <- combn(predictors, i)
  tmp <- apply(tmp, 2, paste, collapse=" + ")
  tmp <- paste0("logViolent~PctPopUnderPov + ", tmp)
  formulas[[i]] <- tmp
}
formulas <- unlist(formulas)
formulas <- sapply(formulas, as.formula)
models <- lapply(formulas, lm, data=train_data)

bics <- sapply(models, BIC)
r_square <- sapply(models, function(m) summary(m)$r.squared)
adj_r_square <- sapply(models, function(m) summary(m)$adj.r.squared)
formula_vector <- vapply(formulas, function(f) paste(deparse(f), collapse = ""), character(1))

# build the frame
model_ranking <- data.frame(
  formula = formula_vector,
  r.square = r_square,
  adj.r.square = adj_r_square,
  BIC = bics
)
model_ranking <- model_ranking[order(model_ranking$BIC), ]
head(model_ranking, 10)
```

We then run the multivariate regression equation

```{r show best model 2}
# Print best model
best <- which.min(model_ranking$BIC)
best_pred <- model_ranking$formula[best]
cat("\nBest model:\n")
cat(best_pred, "\n")
cat("BIC:", round(model_ranking$BIC[best], 2), "\n")
cat("Adjusted R²:", round(model_ranking$adj.r.square[best], 4), "\n")

fit_multi <- lm(best_pred, data = train_data)
multi_var_summary <- summary(fit_multi)
multi_var_summary
```

### Partial Regression Plots

```{r partial-regression-plots2, fig.width=10, fig.height=8}
predictor_list <- row.names(multi_var_summary$coefficients[-1,])
plots <- lapply(predictor_list, function(predictor) {
    partial_regression_plot(train_data, "ViolentCrimesPerPop", predictor, predictor_list)
}
)

# Print 9 plots per pg
print(wrap_plots(plots, ncol = 3))
```

### Interaction Terms Selection

Following the protocol, we add all interaction terms of the predictor variables with our main predictor variable *PctPopUnderPov* and evaluate their significance. We choose the best one. -> in ons protocol staat 1 of meer en hier zijn meerdere significant?

```{r interaction term selection 2}
selected_vars <- row.names(multi_var_summary$coefficients[-(1:2),])
interaction_terms <- paste("PctPopUnderPov", selected_vars, sep = ":")
 
formulas <- sapply(interaction_terms, function(i) {
  paste0(best_pred, " + ", i)
})

formulas <- lapply(formulas, as.formula)
models <- lapply(formulas, lm, data=train_data)

interaction_models_form <- vapply(formulas, function(f) 
  paste(deparse(f), collapse = ""), character(1))
summary_val_extraction <- function(x, item) {
  tmp <- summary(x)$coefficients
  tmp[nrow(tmp), item]
}
p_vals_interaction <- sapply(models, function(m) 
  summary_val_extraction(m, "Pr(>|t|)"))
t_vals_interaction <- sapply(models, function(m) 
  summary_val_extraction(m, "t value"))

bics <- sapply(models, BIC)
r_square <- sapply(models, function(m) summary(m)$r.squared)
adj_r_square <- sapply(models, function(m) summary(m)$adj.r.squared)
delta_adj_r_square <- sapply(models, function(m) 
  summary(m)$adj.r.squared - summary(fit_multi)$adj.r.squared)

interaction_table <- data.frame(
  p.vals = p_vals_interaction,
  t.vals = t_vals_interaction,
  r.square = r_square,
  adj.r.square = adj_r_square,
  delta.adj = delta_adj_r_square,
  BIC = bics
)
interaction_table <- interaction_table[order(interaction_table$p.vals), ]
interaction_table
  
best_interaction <- row.names(interaction_table[1,])
```

## Multivariate Model

Based on the model selection procedure, we fit the multivariate model including the selected interaction term.

```{r final model2}
# Estimate model with interaction
#formula_final <- as.formula(paste("logViolent ~", 
                                  #paste(predictor_list, collapse = " + "), "+",
                                  #paste(best_interaction, collapse = " + ")))


# even handmatig aan modelselectie doen
formula_final <- as.formula(paste("logViolent ~", 
                                  paste(predictor_list, collapse = " + "), "+",
                                  "PctPopUnderPov:racepctblack + PctPopUnderPov:PctLess9thGrade + PctPopUnderPov:PctImmig + PctPopUnderPov:PctBSorMore"))
fit_final <- lm(formula_final, data = train_data)
summary(fit_final)

# we kunnen opteren om PctPopUnderPov:PctImmig als interactie te laten vallen
formula_final <- as.formula(paste("logViolent ~", 
                                  paste(predictor_list, collapse = " + "), "+",
                                  "PctPopUnderPov:racepctblack + PctPopUnderPov:PctLess9thGrade + PctPopUnderPov:PctBSorMore"))

fit_final <- lm(formula_final, data = train_data)
summary(fit_final)

# confint
print(confint(fit_final))
```

### Multicollinearity Check

Before checking model assumptions, we first assess multicollinearity using the Variance Inflation Factor (VIF) and remove a variable if necessary.
```{r multicoll check2}
library(car)
# practicum: car::vif(fit)
vif <- vif(fit_final)
print(vif)
```

We see that our model performs only a little less well, but this way we did account for multicollinearity and our estimates are correct.

```{r compare2}
# Compare models
cat("Comparison of models:\n")
cat("Original model adjusted R²: ", round(summary(fit_multi)$adj.r.squared, 4), "\n")
cat("interaction term model adjusted R²:  ", round(summary(fit_final)$adj.r.squared, 4), "\n")

```

### Assumption checks final model

```{r final-model-diagnostics, fig.width=10, fig.height=8}
par(mfrow = c(2, 2))

#Residuals vs Fitted
plot(fit_final$fitted.values, fit_final$residuals,
     xlab = "Fitted values", ylab = "Residuals",
     main = "Residuals vs Fitted (Final Model)")
abline(h = 0, col = "red", lty = 2)
lines(lowess(fit_final$fitted.values, fit_final$residuals), col = "blue")

# Squared residuals vs Fitted
plot(fit_final$fitted.values, fit_final$residuals^2,
     xlab = "Fitted values", ylab = "Squared Residuals",
     main = "Squared Residuals vs Fitted")
lines(lowess(fit_final$fitted.values, fit_final$residuals^2), col = "blue")

# QQ-plot
qqnorm(fit_final$residuals, main = "Normal Q-Q Plot (Final Model)")
qqline(fit_final$residuals, col = "red")

par(mfrow = c(1, 1))
```


```{r outliers vs population2}
# outliers are more present in small pop?
outlier_data <- train_data[outliers_simple, .(population, ViolentCrimesPerPop, PctPopUnderPov)]
print(outlier_data)

# Residuals vs population
plot(train_data$logpopulation, fit$residuals,
     xlab = "log(population)", ylab = "Residuals",
     main = "Residuals vs log(population)")
abline(h = 0, col = "red", lty = 2)
lines(lowess(train_data$logpopulation, fit$residuals), col = "blue")

plot(train_data$logpopulation, stud_res,
     xlab = "log(population)", ylab = "Residuals",
     main = "Studentized Residuals vs log(population)")
abline(h = 0, col = "red", lty = 2)
lines(lowess(train_data$logpopulation, stud_res), col = "blue")

```



## diagnostics

deze kan ook al eerder gebruikt worden, die geeft echt alles en moet je niet apart dingen gaan berekenen zoals hieronder/boven (uit een van zijn pc labs). hierin kan je goed zien dat er toch redelijk wat influential outliers zijn, dus dat robust wel is.

```{r}
library(olsrr)
diagplots <- olsrr::ols_plot_diagnostics(fit_final, print_plot = TRUE)
```

Diagnostic plots (figuur) reveal several potential outliers and high-leverage points. To assess the impact of these points, we fit a robust regression using Bisquare weights. 

```{r robust-inference}
library(sandwich)
library(lmtest)
library(MASS)

robust <- rlm(formula(fit_final), data = train_data, psi = psi.bisquare)
summary(robust, method = "XtX")
```

```{r}
par(mfrow=c(2,2))
plot(fit_log)
par(mfrow=c(2,2))
plot(robust, which = 1)

qqnorm(resid(robust))
qqline(resid(robust))

```

A comparison of the coefficients reveal no substantial differences, indicating that the influential points are not the result of gross errors. <hier moeten nog extra checks van influence on inferences bij>.
The identified leverage-points can be called 'good leverages' as they exhibit high leverage but their residuals are still small, this even improves the precision of the regression coefficients. (zie referentie)

```{r influence inference}
# Compare OLS vs Robust coefficients
comparison <- data.frame(
  OLS = coef(fit_final),
  Robust = coef(robust),
  Difference = coef(fit_final) - coef(robust)
)

print(round(comparison, 4))
```


### Outlier and Influence Diagnostics 

We use several diagnostic measures to identify influential observations

```{r influence diagnostics}
# Calculate diagnostics
stud_res_final <- rstudent(fit_final)
leverage <- hatvalues(fit_final)
p <- length(coef(fit_final))
n_train <- nrow(train_data)
leverage_threshold <- 2 * p / n_train
cooks_d <- cooks.distance(fit_final)
dffits_val <- dffits(fit_final)
dffits_threshold <- 2 * sqrt(p / n_train)
dfbetas_val <- dfbetas(fit_final)
dfbetas_threshold <- 2 / sqrt(n_train)

# dataframe
diagnostics <- data.frame(
  obs = 1:n_train,
  population = train_data$population,
  # zowel studentized deleted residuals als studentized residuals insteken?
  # DFBETAS ook insteken (per beta kan je dat bepalen) (chapter 10 Diagnostics slide 40)
  stud_residual = stud_res_final,
  leverage = leverage,
  cooks_d = cooks_d,
  dffits = dffits_val
)

# Flag observations
diagnostics$outlier_residual <- abs(diagnostics$stud_residual) > 2
diagnostics$high_leverage <- diagnostics$leverage > leverage_threshold
diagnostics$high_cooks <- diagnostics$cooks_d > 4 / n_train
diagnostics$high_dffits <- abs(diagnostics$dffits) > dffits_threshold

# summ
cat("Outliers by studentized residuals (|r*| > 2):", sum(diagnostics$outlier_residual), "\n")
cat("High leverage observations (h >", round(leverage_threshold, 4), "):", 
    sum(diagnostics$high_leverage), "\n")
cat("High Cook's distance (D >", round(4/n_train, 4), "):", 
    sum(diagnostics$high_cooks), "\n")
cat("High DFFITS (|DFFITS| >", round(dffits_threshold, 4), "):", 
    sum(diagnostics$high_dffits), "\n")
```

```{r influential observations}
# find influent obs
influential <- diagnostics[diagnostics$high_cooks | diagnostics$high_dffits, ]
influential <- influential[order(-influential$cooks_d), ]
print(head(influential[, c("obs", "population", "stud_residual", "leverage", "cooks_d", "dffits")], 10))
```

```{r influence plot, fig.width=8, fig.height=6}
# Influence plot
plot(leverage, stud_res_final, 
     xlab = "Leverage", ylab = "Studentized Residuals",
     main = "Influence Plot",
     cex = sqrt(cooks_d) * 10)
```

```{r dfbetas plots, fig.width=10, fig.height=8}
# DFBETAS plots
par(mfrow = c(2, ceiling(ncol(dfbetas_val)/2)))
for(j in 1:ncol(dfbetas_val)) {
  plot(dfbetas_val[, j], 
       ylab = paste("DFBETAS -", colnames(dfbetas_val)[j]),
       main = colnames(dfbetas_val)[j])
}
par(mfrow = c(1, 1))
```



## interpretation final model

Our final model is:`r formula_final`.
```{r}
summary(fit_final)
print(confint(fit_final))
```

```{r}
library(stdmod)
b <- coef(fit_final)
mean_race <- mean(train_data$racepctblack)
mean_9thgrade <- mean(train_data$PctLess9thGrade)
mean_bsormore <- mean(train_data$PctBSorMore)
mean_poverty <- mean(train_data$PctPopUnderPov)

coef_mean <- b["PctPopUnderPov"] +
      b["PctPopUnderPov:racepctblack"]    * mean_race +
      b["PctPopUnderPov:PctLess9thGrade"] * mean_9thgrade +
      b["PctPopUnderPov:PctBSorMore"]     * mean_bsormore
percentage_change <- (exp(coef_mean) - 1) *100
```

#### notes on interpretation

Our final model is a log-linear model, this makes interpretation of the coefficients less intuitive. We will start by giving the coefficients that express the estimated change in the log of the expected violent crime rate per 100k population with an increase of the predictor variable by 1 unit. To ease interpretation we will back transform this coefficient and multiply it by 100 to express the estimated percentage change of the mean violent crime rate / 100k when the predictor variable is increased by 1 unit. The intercept on its own is not interpretable as it would require all predictor variables (and interaction terms) to be zero. This is not in the scope of our model. If it were, the intercept of `r b["(intercept)"]` could be interpreted as the estimated log of expected crime rate when all predictor variables are 0.
There is no use in interpreting interaction-term coefficients on their own, as they indicate the effect of one predictor on the other, but have no direct effect on its own.


#### interpretation of PctPopUnderPov


The effect of PctPopUnderPov varies with racepctblack, PctLess9thGrade and PctBsorMore through the interaction terms. This means that the effect of PctPopUnderPov is not simply given by its coefficient, but instead we can look at the estimated effect of PctPopUnderPov on the log of expected violent crimes as `r summary(fit_final)$coefficients[2,1]` + `r summary(fit_final)$coefficients[7,1]` * racepctblack + `r  summary(fit_final)$coefficients[8,1]` * pctless9thgrade + `r summary(fit_final)$coeffecients[9,1]` * cptbsormore. Interpretation is more intuitive if we back transform the logdata.The effect of an increase in PctPopUnderPop with one unit (one percent) on violent crimes per 100k is then calculated by:  exp(`r b["PctPopUnderPov"]` + `r b["PctPopUnderPov:racepctblack"]` * racepctblack + `r b["PctPopUnderPov:PctLess9thGrade"]` * pctless9thgrade + `r b["PctPopUnderPov:PctBSorMore"]` * cptbsormore) -1 when all other variables are held constant. 
If we take for example the mean of the 3 interacting terms to calculate the effect of PctPoponderpov when the interacting variables are held at their average and we back transform it we can find `r exp(coef_mean) -1`.
We can interpret the estimated percentage change, `r percentage_change`%, as the estimated increase in expected value of violent crimes (per population of 100k) per percentage increase of pop under pov, when the interacting variables are held at their average and all other variables are held constant. 



#### interpretation of PctLess9thGrade

```{r}
set.seed(123)
CI_9thgrade <- cond_effect_boot(fit_final,
            x = "PctLess9thGrade", w = "PctPopUnderPov", nboot = 2000)
ci_lower <- exp(CI_9thgrade$"CI Lower"[CI_9thgrade$Level == "Medium"]) - 1 
ci_upper <- exp(CI_9thgrade$"CI Upper"[CI_9thgrade$Level == "Medium"]) - 1



```


As mentioned above, PctLess9thGrade and PctPopUnderPov interact. The effect of PctLess9thGrad is therefore impacted by the level of PctPopUnderPov: `r b["PctLess9thGrade"]` + `r b["PctPopUnderPov:PctLess9thGrade"]` * PctPopUnderPov. This interaction effect is reinforcing, meaning that an increase in PctPopUnderPov would lead to a more negative slope for PctLess9thGrade. Taking the mean of PctPopUnderPov the interaction-adjusted coefficient for Pctless9thegrade is `r b["PctLess9thGrade"] + b["PctPopUnderPov:PctLess9thGrade"] * mean_poverty`. Increasing Pctless9thGrade by one percent (one unit), we estimate that the expected value of violent crimes (per 100k) decreases by `r (exp(b["PctLess9thGrade"] + (b["PctPopUnderPov:PctLess9thGrade"] * mean_poverty)) -1) * 100`% (original scale) when PctPopUnderPov is held at its mean and all other variables are held constant. We can find a 95% confidence interval using cond_effect_boot() from package *stdmod* of [`r ci_lower` , `r ci_upper`]. We can therefore say that with a .95 confidence coefficient, we estimate that the percentage change of expected crime rates is somewhere between `r ci_lower * 100`% and `r ci_upper * 100`%. Note that this is a pointwise confidence interval for when PctPopUnderPov is held at its mean and all other variables are held constant. However we see that the coefficient of the main effect in the model is not significant, but still included because of the interaction term. We also see that the multicollinearity increases, this can increase standard errors and lead to unstable coefficient estimates. It therefore provides a possible explanation to the sign of the estimates that are incosistent with theoretical expectations.




#### interpretation of PctBSorMore

There is also an interaction term included between PctBSorMore and PctPopUnderPov. The interpretation is similar to that of PctLess9thGrade. The conditional effect on of PctBSorMore on the log expected violent crime rate is given by: `r b["PctBSorMore"]` + `r b["PctPopUnderPov:PctBSorMore"]`* PctPopUnderPov. Both coefficients are negative, indicating a reinforcing effect: increases in PctPopUnderPov enforces the negative effect of PctBSorMore. Similarly to before we can take the mean of PctPopUnderPov and estimate the conditional effect of PctBSorMore on the log expected value of crime rate per unit increase of PctBSorMore, when keeping poverty at its mean and all other variables constant: `r b["PctBSorMore"]` + `r b["PctPopUnderPov:PctBSorMore"] * mean_poverty`. Undoing the log transformation we get `r (exp(b["PctBSorMore"] + b["PctPopUnderPov:PctBSorMore"] * mean_poverty) - 1)* 100`%, which can be interpreted as the estimated percent change in expected crime rate by increasing PctBSorMore by one unit (1%), keeping PctPovUnderPop at its mean and all other variables constant. Thus if, under the conditions stated above, a higher percentage of the population has a Bachelors degree or higher, the estimated mean crime rate decreases and this effect is more pronounced for higher levels of PctUnderPov.
```{r}
set.seed(123)
cond_effect_boot(fit_final,
            x = "PctBSorMore", w = "PctPopUnderPov", nboot = 2000)
```



#### interpretation of racepctblack

We follow the same logic for racepctblack as for the previous 2. However we now see an interference interaction effect: the conditional effect of racepctblack is given by: `r b["racepctblack"]` + `r b["PctPopUnderPov:racepctblack"]` * PctPopUnderPov. If we look at the main effect of racepctblack (PctPopUnderPov = 0), we see a positive effect, where we see a negative contribution of the interaction term: the slope of the response function against racepctblack decreases for higher levels of PctPopUnderPov. For a higher percentage of people living under the poverty line, the estimated effect of percentage of black people on violent crime rates is lower than when there is a lower percentage of people living under the poverty line. If we look at the conditional effect of racepctblack when PctpovUnderPop is held at its mean we get: `r b["racepctblack"]` + `r b["PctPopUnderPov:PctBSorMore"] * mean_poverty`. Exponentiating this expression to return to the original scale we get an estimated percentage change of `r (exp(b["racepctblack"] +  b["PctPopUnderPov:racepctblack"] * mean_poverty)-1) *100`% of the expected crime rates (100k) by increasing the racepctblack by one unit (1%), keeping PctPovUnderPov at its mean and all other variables constant. Increasing levels of PctPovUnderPov would result in a smaller positive effect of racepctblack than lower levels of PctPopUnderPov.

```{r}
set.seed(123)

cond_effect_boot(fit_final,
            x = "racepctblack", w = "PctPopUnderPov", nboot = 2000)


```


#### interpretation of PctImmig 

PctImmig is not involved in any interaction term, therefore we can interpret the main effect `r b["PctImmig"]` on its own. Exponentiating and multiplying by 100 this coefficients we get: `r (exp(b["PctImmig"]) - 1)* 100`. The exponentiated 95% confidence interval is [`r exp(confint(fit_final)[6,1]) - 1` , `r exp(confint(fit_final)[6,2]) -1 `]. With confidence coefficient .95 we estimate that the percentage change in expected crime rates per 100k population per unit increase in PctImmig when keeping all other variables constant will be somewhere between `r (exp(confint(fit_final)[6,1]) - 1) * 100`% and `r (exp(confint(fit_final)[6,2]) -1) * 100`%.


## Summary
Dusja multivariate model stuk beter dan univariate model als je kijkt naar de tabel

```{r summary}
# summary

mse_final <- mean(fit_final$residuals^2)
summary_results <- data.frame(
  Model = c("Simple (PctPopUnderPov only)", "Final Multivariate"),
  R_squared = c(round(summary(fit)$r.squared, 4),
                      round(summary(fit_final)$r.squared, 4)),
  Adj_R_squared = c(round(summary(fit)$adj.r.squared, 4),
                          round(summary(fit_final)$adj.r.squared, 4)),
  MSE = c(round(mse_simple, 2), round(mse_final, 2))
)

kable(summary_results, caption = "Comparison of Simple and Final Multivariate Models")
```

## validation
Using the holdout set, we compute the Mean Squared Prediction Error (MSPR) and comparing it to the Mean Squared Error (MSPR) when the model is used to predict data in the training set.


```{r model validation}
# Predictions on test set
# we back transform the data to the normal scale
#test_data$logViolent <- log(test_data$ViolentCrimesPerPop + 1) is niet nodig
pred <- exp(predict(fit_final, newdata = test_data))
pred_interval <- predict(fit_final, newdata = test_data, interval = "prediction", level = 0.95)

# MSPR 
mspr <- mean((test_data$ViolentCrimesPerPop - pred)^2)

# MSE training
mse_final <- mean(fit_final$residuals^2)

cat("MSPR (training set):", round(mse_final, 2), "\n")
cat("MSPR (test set):", round(mspr, 2), "\n")
cat("Ratio MSPR/MSE:", round(mspr/mse_final, 4), "\n")

```
pred_interval

```{r prediction interval}
inside <- test_data$logViolent >= pred_interval[, "lwr"] & test_data$logViolent <= pred_interval[, "upr"]
cat("Fraction of datapoints in prediction interval:", mean(inside), "\n")

hist(pred_interval[, "upr"] - pred_interval[, "lwr"],
     main = "Width prediction interval",
     xlab = "Width prediction interval",
     xlim = c(2.95, 3.15),
     breaks = 50)

df_prediction <- data.frame(observed = exp(test_data$logViolent), predicted = exp(pred))

ggplot(df_prediction, aes(observed, predicted))+
  geom_point()+
  geom_smooth(se = FALSE)+
  geom_abline(intercept = 0, slope = 1, color = "red")+
  theme_bw() +
  labs(x = "number of violent crimes per 100K population observed",
       y = "number of violent crimes per 100K population predicted")
```

```{r model validation and population size}
logpop_values <- seq(4.1, 6, 0.1)

mspr_fun <- function(logpop, data, fit_final){
  # filtering
  data_filtered <- data[data$logpopulation < logpop + 0.1 & data$logpopulation > logpop - 0.1, ]
  # Predictions on test set
  pred <- exp(predict(fit_final, newdata = data_filtered))
  mspr <- mean((data_filtered$ViolentCrimesPerPop - pred)^2)
}


mspr_values_test <- sapply(logpop_values, FUN=mspr_fun, data=test_data, fit_final=fit_final)
mspr_values_train <- sapply(logpop_values, FUN=mspr_fun, data=train_data, fit_final=fit_final)

df_plot_logpop_mspr <- data.frame(logpop = logpop_values, mspr_values_test, mspr_values_train)

ggplot(df_plot_logpop_mspr, aes_string(logpop_values,mspr_values_test)) +
    geom_point(alpha = 0.6, size = 1.7) +
    geom_smooth(method = "loess", color = "red", se = FALSE)+
    theme_bw(base_size = 8) +
    labs(title = "Mean squared prediction error for test data vs logpop", x = "logpop", y = "mspr")
ggplot(df_plot_logpop_mspr, aes_string(logpop_values,mspr_values_train)) +
    geom_point(alpha = 0.6, size = 1.7) +
    geom_smooth(method = "loess", color = "red", se = FALSE)+
    theme_bw(base_size = 8) +
    labs(title = "Mean squared prediction error for training data vs logpop", x = "logpop", y = "mspr")
```

```{r validation plot, fig.width=8, fig.height=6}
# validation
plot(test_data$logViolent, pred,
     xlab = "Observed ViolentCrimesPerPop (log scale)", ylab = "Predicted",
     main = "Observed vs Predicted")

# R-squared on test set
ss_res <- sum((test_data$logViolent - pred)^2)
ss_tot <- sum((test_data$logViolent - mean(test_data$logViolent))^2)
r2_test <- 1 - ss_res/ss_tot
cat("\nR² on test set (log scale):", round(r2_test, 4), "\n")

cat("R² on training set (log scale):", round(summary(fit_final)$r.squared, 4), "\n") 
```


# Statistical discussion

The dataset is not random or representative of all US communities. The main missing data source is ViolentCrimesPerPop, where 221 observations are missing because of incomplete rape reporting in Midwestern States. As violent crime is calculcated as the sum of a few components, including rape, missing values are not random and come from  state-specific reporting. Removing these observations thus leads to the underrepresentation of  certain regions and could bias national estimates.

Second, the LEMAS survey includes all police departments with at least 100 officers and only a random sample of smaller ones. Because of this, large communities (and thus more urban communities) are overrepresented, but many small towns are not represented in the dataset. Thus, relationships found in the analysis should be interpreted at the city-level, and may be less likely to translate to the rural communities.

Another caveat is that the FBI’s data is from 1995, while the Census populations containing demographic variables are from 1990. This induces measurement error in the dependent variable. As the violent crime rate is calculated using 1995 population estimates in the denominator, the SE predictors are from 1990. Thus, communities that have a sizeable population growth or decline between 1990 and 1995 have very biased crime rates. Growing communities have understated rates, decline communities overstated rates.  Also, communities with larger population differences will have more noisy crime rate measurements (leading to heterosked?). This leads to measurement error in the dependent variable, leading to heterosked and outliers. (not entirely sure about this paragraph).

Our regression analysis is thus valid  for a subset of communities with complete data, but should not be generalized to all U.S. communities.



# References

Becker GS (1968) Crime and Punishment: An Economic Approach. J Polit Econ 76: 169–217

# References dataset

U. S. Department of Commerce, Bureau of the Census, Census Of Population And Housing 
1990 United States: Summary Tape File 1a & 3a (Computer Files),

U.S. Department Of Commerce, Bureau Of The Census Producer, Washington, DC and 
Inter-university Consortium for Political and Social Research Ann Arbor, Michigan. 
(1992)

U.S. Department of Justice, Bureau of Justice Statistics, Law Enforcement Management 
And Administrative Statistics (Computer File) U.S. Department Of Commerce, Bureau Of 
The Census Producer, Washington, DC and Inter-university Consortium for Political and 
Social Research Ann Arbor, Michigan. (1992)

U.S. Department of Justice, Federal Bureau of Investigation, Crime in the United 
States (Computer File) (1995)

Redmond, M. A. and A. Baveja: A Data-Driven Software Tool for Enabling Cooperative 
Information Sharing Among Police Departments. European Journal of Operational Research 
141 (2002) 660-678.

Rousseeuw, P. J., & van Zomeren, B. C. (1990). Unmasking Multivariate Outliers and Leverage Points. Journal of the American Statistical Association, 85(411), 633–639. https://doi.org/10.1080/01621459.1990.10474920
