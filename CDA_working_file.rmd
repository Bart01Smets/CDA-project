---
title: "Analysis of Continuous Data project"
author: "Thomas Sertijn, Bart Smets, Ilja Van Bever, Lieselot Van de Putte"
date: "2025-11-09"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(message = FALSE, warning = FALSE,
                      echo = TRUE)
```

# Protocol - Univariate part

```{r echo=FALSE}
library(knitr)
library (glue)
library(dplyr)
```

## Research question

During this research, we want to investigate how socio-economic disadvantage relates to violent crime rates. More specifically we want to explore the association between poverty and violent crime rates in the USA.

In his seminal work, Becker (1968) stated that the decision to commit crime is a rational choice where people weigh the benefits and costs against each other. It could then be argued that the incentive to commit crime is higher for people who have a lower income, as the benefits are larger for this group. Following this, we would then also expect that in communities with a higher poverty rate, there will also be higher crime rates. Depending on the results of our analysis, these results could be used to inform relevant policies. It would, for example, give another argument for the implementation of redistributive policies: if an effect is found, policymakers should take this reduction in violent crime into account, next to an economic benefit. Our analysis hopes to shed further light on this issue.

For the purpose of our research question, the following predictor variables have been selected:

-   **PctPopUnderPov**: percentage of people under the poverty level (main predictor).
-   **perCapInc**: per capita income. While similar to pctunderpoverty, this takes the whole income distribution into account and not just the lower end. If this average is lower, then we expect more crime to happen.
-   **PctEmploy**: percentage of people 16 and over who are employed. We could argue that if more people are employed less people have an incentive to commit crime.
-   **PctLess9thGrade**: percentage of people 25 and over with less than a 9th grade education. Education leads to a higher socio-economic standing, which would suggest that people have less reason to commit crime. We choose this variable for now, but as an alternative we could later use one of the following two variables if we would find them better suited as predictors: **PctNotHSGrad** (percentage of people 25 or over, that have not graduated highschool) or **PctBSorMore** (percentage of people 25 or over, with at least a bachelor's degree).
-   **NumImmig**: total number of people known to be foreign born. Immigrants commiting more crimes is a commonly used right-wing argument against migration, and relevant as immigrants are often from a 'lower' socio-economic background.
-   **racepctblac**: percentage of population that is african american. It is a common right wing argument as well that black people commit crime, because they are from a 'lower' socio-economic background.
-   **agePct12t29**: percentage of population that is 12-29 in age. We include this because young people have had less time to build up their socio-economic status, as well as their brain being less developed, and might thus commit more crime.

## Design of the study


## Descriptive analysis

To get a first impression of the data, a descriptive analysis will be performed for the candidate predictor variables (all continuous). The datasets are checked for missing values. The most common univariate statistics are calculated: the mean, the standard deviation, the minimum, the first quartile, the median, the third quartile and the maximum.

The distributions of the variables are visualized by boxplots, QQ plots and histograms. Outliers are identified using Tukey’s 1.5 x IQR rule. For the univariate descriptive statistics also the population size of the communities is considered. The population size can influence the reliability of the data points: small communities can have a higher probability to have more extreme values of the predictor and response variables by the fact that the denominator in the response variable (total number of violent crimes per 100K population) is smaller. In the regression phase this will be used to investigate the outlier values.

To find what the relationship is between the main predictor variable and the potential extra predictor variables, scatter plots with smoothers are made for the bivariate relationships and correlations are checked.

## Linear regression

Before performing linear regression and building models, the dataset is split into a training set (80% of the data) and a test set (20% of the data).

To investigate the association between the main predictor variable and the response variable, a linear regression is fitted and the output is evaluated. The various statistics are calculated and discussed: estimate regression coefficients, the F-statistics (/t-statistics), the R squared, the MSE, the p-value, the confidence interval and standard error of the slope. We first present the general formula here, before we fill in the specific variables.

$$
Y_i = \beta_0 + \beta_1X_i + \epsilon_i 
$$

$$
ViolentCrimesPerPop_i = \beta_0 + \beta_1pctpopUnderPov_i + \epsilon_i 
$$

Confidence intervals are constructed. Based on this, outliers can be identified. Subsequently, the outliers are further evaluated, e.g. are outliers linked to communities with a small population size.

## Assumption checks

For linear regression, multiple assumptions, such as linearity, independence of errors, homoscedasticity (constant variance of errors), and normality of errors, are made. During this research these assumptions have to be checked by: Plotting residuals vs. fitted values for the linearity and independence of errors, squared residuals vs. fitted values for homoscedasticity checks, normality checks by qq-plot of the residuals. To also take leverage into account, the studentized residuals will be plotted.

# Protocol - Multivariate part

## Model building
Forward stepwise regression
Evaluation of adjusted R-squared, AIC, SBC
Partial regression plots? In which functional form we let a variable enter the model?

## Model fit and outliers
PRESS, studentized residual plots (transformations needed?), bijv. QQ-plots to predicted value of y/log(y), 
Also DFFITS, Cook's Distance, DFBETAS -> welke outliers hebben een grote invloed? Deleted residuals?

## Interpretation of the parameters


```{r echo=FALSE}
# Create the table in R
schedule <- data.frame(
  Deadline = c("3/11", "10/11", "17/11", "24/11", "24/11", "1/12", "1/12", "1/12", "8/12", "8/12", "8/12"),
  Subject = c("Data extraction",
              "Descriptive analyses",
              "Model building",
              "Model interpretation",
              "Prediction with linear model",
              "Statistical discussion linear model",
              "Fitting GLM",
              "Fitting the final model",
              "Prediction with GLM",
              "Statistical discussion GLM",
              "Final conclusion and discussion"),
  Final_responsibility = c("Thomas",
                           "Ilja",
                           "Bart",
                           "Lieselot",
                           "Ilja",
                           "Bart",
                           "Lieselot",
                           "Thomas",
                           "Ilja",
                           "Thomas",
                           "Lieselot")
)

# Print the table
kable(schedule, caption = "Project Schedule Overview", align = c('c', 'l', 'c'))
```

# Data extraction:
---- load data ----
```{r}
library(data.table)
violent_crimes_table <- fread("curl https://archive.ics.uci.edu/static/public/211/communities+and+crime+unnormalized.zip")
```
---- remotely get variable names ---- 
```{r}
library(dplyr)
library(stringr)
library(rvest)
url <- "https://archive.ics.uci.edu/dataset/211/communities+and+crime+unnormalized"

# Read the HTML page
page <- read_html(url)

# Extract all text from the page
text <- page %>% html_text()

# Split into lines
lines <- str_split(text, "\n")[[1]]

start <- grep("Additional Variable Information", lines, ignore.case = TRUE)
end   <- grep("Summary Statistics:", lines, ignore.case = TRUE)

# only retain the lines starting with --
var_lines <- lines[str_starts(str_trim(lines), "--")]
# remove the --
var_names <- sapply(strsplit(var_lines, "--"), function(x) str_trim(x[2]))
# only retain the variable names by cutting everything after the :
var_names <- str_extract(var_names, "^[^:]+")
```
----------------------------------
#remove in final product
----------------------------------
```{r}
# variable_names <- list("communityname","state","countyCode", "communityCode", "fold", "population", "householdsize", 
#                        "racepctblack", "racePctWhite", "racePctAsian", "racePctHisp", "agePct12t21", "agePct12t29", "agePct16t24",
#                        "agePct65up", "numbUrban", "pctUrban", "medIncome", "pctWWage", "pctWFarmSelf", "pctWInvInc", "pctWSocSec",
#                        "pctWPubAsst", "pctWRetire", "medFamInc", "perCapInc", "whitePerCap", "blackPerCap", "indianPerCap", "AsianPerCap", 
#                        "OtherPerCap", "HispPerCap", "NumUnderPov", "PctPopUnderPov", "PctLess9thGrade", "PctNotHSGrad", "PctBSorMore", 
#                        "PctUnemployed", "PctEmploy", "PctEmplManu", "PctEmplProfServ", "PctOccupManu", "PctOccupMgmtProf", "MalePctDivorce",
#                        "MalePctNevMarr", "FemalePctDiv", "TotalPctDiv", "PersPerFam", "PctFam2Par", "PctKids2Par", "PctYoungKids2Par", 
#                        "PctTeen2Par", "PctWorkMomYoungKids", "PctWorkMom", "NumKidsBornNeverMar", "PctKidsBornNeverMar", "NumImmig",
#                        "PctImmigRecent", "PctImmigRec5", "PctImmigRec8", "PctImmigRec10", "PctRecentImmig", "PctRecImmig5", "PctRecImmig8",
#                        "PctRecImmig10", "PctSpeakEnglOnly", "PctNotSpeakEnglWell", "PctLargHouseFam", "PctLargHouseOccup", "PersPerOccupHous",
#                        "PersPerOwnOccHous", "PersPerRentOccHous", "PctPersOwnOccup", "PctPersDenseHous", "PctHousLess3BR", "MedNumBR",
#                        "HousVacant", "PctHousOccup", "PctHousOwnOcc", "PctVacantBoarded", "PctVacMore6Mos", "MedYrHousBuilt",
#                        "PctHousNoPhone", "PctWOFullPlumb", "OwnOccLowQuart", "OwnOccMedVal", "OwnOccHiQuart", "OwnOccQrange", "RentLowQ",
#                        "RentMedian", "RentHighQ", "RentQrange", "MedRent", "MedRentPctHousInc", "MedOwnCostPctInc", "MedOwnCostPctIncNoMtg",
#                        "NumInShelters", "NumStreet", "PctForeignBorn", "PctBornSameState", "PctSameHouse85", "PctSameCity85",
#                        "PctSameState85", "LemasSwornFT", "LemasSwFTPerPop", "LemasSwFTFieldOps", "LemasSwFTFieldPerPop", "LemasTotalReq",
#                        "LemasTotReqPerPop", "PolicReqPerOffic", "PolicPerPop", "RacialMatchCommPol", "PctPolicWhite", "PctPolicBlack",
#                        "PctPolicHisp", "PctPolicAsian", "PctPolicMinor", "OfficAssgnDrugUnits", "NumKindsDrugsSeiz", "PolicAveOTWorked",
#                        "LandArea", "PopDens", "PctUsePubTrans", "PolicCars", "PolicOperBudg", "LemasPctPolicOnPatr", "LemasGangUnitDeploy",
#                        "LemasPctOfficDrugUn", "PolicBudgPerPop", "murders", "murdPerPop", "rapes", "rapesPerPop", "robberies", "robbbPerPop",
#                        "assaults", "assaultPerPop", "burglaries", "burglPerPop", "larcenies", "larcPerPop", "autoTheft", "autoTheftPerPop", 
#                        "arsons", "arsonsPerPop", "ViolentCrimesPerPop", "nonViolPerPop")
```
---------------------------------------
# end of removable part
---------------------------------------

```{r}
colnames(violent_crimes_table) <- var_names 
```

```{r}
crimes_table_subset <- violent_crimes_table %>% 
  dplyr::select(communityname,state,countyCode, communityCode, fold, population, 
         PctPopUnderPov, perCapInc, PctEmploy, PctLess9thGrade, PctNotHSGrad, PctBSorMore,
         NumImmig, racepctblack, agePct12t29, ViolentCrimesPerPop
         )
```

# Design

The dataset combines 1990 U.S. Census socio-economic data, 1990 law enforcement data from the Law Enforcement Management and Admin Stats (LEMAS) survey, and 1995 FBI crime data, thereby creating two cohorts. For the FBI crime data, it is mentioned that states with a lower amount of visitors have a lower per capita crime rate and vice verse. The LEMAS survey covers all communities with police departments of at least 100 officers and a random sample of smaller departments. If communities were absent from either the crime or census datasets (e.g., those with very small departments), then they were removed. All demographic data is from 1990, but per-capita crime rates use 1995 population counts. Finally, rape counts, a component of violent crime, are missing in some states due to inconsistent reporting, which resulted in missing total violent crime values for those states. We will investigate whether this missingness has probably a large effect on the model and if necessary use imputations.

# Data preparation

```{r, include=FALSE}
library(ggplot2)
library(gtsummary)
library(sjlabelled)
library(tidyr)
```

Since the outcome variable *ViolentCrimesPerPop* (total number of violent crimes per 100K population) is expressed relative to the population size, the variable *NumImmig* is converted (by dividing it by the population size and multiplying by 100%). It's important to mention that this is not an exact transformation, because all demographic
data is from 1990, but per-capita crime rates use 1995 population counts. 
```{r}
crimes_table_subset$ViolentCrimesPerPop <- as.numeric(crimes_table_subset$ViolentCrimesPerPop)
crimes_table_subset$PctImmig <- crimes_table_subset$NumImmig/crimes_table_subset$population*100
crimes_table_subset = crimes_table_subset[,-c('NumImmig', 'fold')]
```
```{r}
sjlabelled::set_label(crimes_table_subset) <- c("communityname", "state", "countyCode", "communityCode", "population", "people under the poverty level (%)", "per capita income ($)", "percentage of people 16 and over who are employed (%)", "percentage of people 25 and over with less than a 9th grade education (%)", "percentage of people 25
or over, that have not graduated highschool (%)", "percentage of people 25 or over, with
at least a bachelor’s degree (%)", "percentage of population that is african american (%)", "percentage of population that is 12-29 in age (%)", "total number of violent crimes per 100K population", "percentage of immigrants (%)")
```


It is examined how many NA values are present in the database.
```{r counting NA values}
crimes_table_subset %>%
  pivot_longer(cols = where(is.numeric), names_to = "variable", values_to = "value") %>%
  group_by(variable) %>%
  summarise(
    NAs = sum(is.na(value))
  )
```

The only variable for which NA values are found is the outcome variable *ViolentCrimesPerPop*. Imputations can not help a lot to handle this. As already mentioned in the section on the study design, many of these NA values are due to the fact that rape counts, a component of violent crime, were not included in the statistics for several states. The rows where the outcome variable has an NA value are removed, as these rows are not useful for the regression. It can be noted that the variables *countyCode* and *communityCode* are also frequently unknown.

```{r identifying NA values}
na_subset <- crimes_table_subset %>%
  filter(is.na(ViolentCrimesPerPop)
  )
na_subset <- na_subset[,-'ViolentCrimesPerPop']
na_subset
```


```{r}
crimes_table_subset = na.omit(crimes_table_subset)
colSums(crimes_table_subset == "?", na.rm = TRUE)
```

# Univariate descriptives

After removing NA values from the database univariate descriptives are calculated, both the missing values and the non-missing values. 

```{r summary statistics}
#str(crimes_table_subset)
#summary(crimes_table_subset)

crimes_table_subset %>%
  pivot_longer(cols = where(is.numeric), names_to = "variable", values_to = "value") %>%
  group_by(variable) %>%
  summarise(
    min = min(value, na.rm = TRUE),
    q25 = quantile(value, 0.25, na.rm = TRUE),
    mean = mean(value, na.rm = TRUE),
    sd = sd(value, na.rm = TRUE),
    q75 = quantile(value, 0.75, na.rm = TRUE),
    max = max(value, na.rm = TRUE),
    n = n(),
    NAs = sum(is.na(value))
  )
```
```{r summary statistics nas}
na_subset %>%
  pivot_longer(cols = where(is.numeric), names_to = "variable", values_to = "value") %>%
  group_by(variable) %>%
  summarise(
    min = min(value, na.rm = TRUE),
    q25 = quantile(value, 0.25, na.rm = TRUE),
    mean = mean(value, na.rm = TRUE),
    sd = sd(value, na.rm = TRUE),
    q75 = quantile(value, 0.75, na.rm = TRUE),
    max = max(value, na.rm = TRUE),
    n = n(),
    NAs = sum(is.na(value))
  )
```

To gain insight into the univariate distributions, boxplots and histograms are generated.

```{r boxplots, fig.width=8, fig.height=12}
numeric_cols <- sapply(crimes_table_subset, is.numeric)
crimes_table_subset_num <- crimes_table_subset[, ..numeric_cols]
par(mfrow = c(4,2))
for(columnname in names(crimes_table_subset_num)){
  column <- crimes_table_subset_num[[columnname]]
  boxplot(column,
          main = columnname
          )
  hist(column,   
       main = columnname,
       xlab = get_label(column)
          )
}
```
```{r boxplots na comparison, fig.width=8, fig.height=12, eval=FALSE, include=FALSE}
numeric_cols_na <- sapply(na_subset, is.numeric)
crimes_table_subset_num_na <- na_subset[, ..numeric_cols_na]
par(mfrow = c(4,2))
for(columnname in names(crimes_table_subset_num_na)){
  column <- crimes_table_subset_num[[columnname]]
  column_na <- crimes_table_subset_num_na[[columnname]]
  boxplot(column,
          main = columnname
          )
  boxplot(column_na,
          main = paste(columnname, "(missing data)")
          )
}
```
To investigate the impact of the missing values, the distribution of the other variables is compared in the missing data vs. the non-missing data. This is done using the histograms. Neither the summary statistics nor the scatter plots indicate that the missing data have characteristics that differ substantially from the non-missing data
```{r histograms na comparison, fig.width=8, fig.height=12}
numeric_cols_na <- sapply(na_subset, is.numeric)
crimes_table_subset_num_na <- na_subset[, ..numeric_cols_na]
par(mfrow = c(4,2))
for(columnname in names(crimes_table_subset_num_na)){
  column <- crimes_table_subset_num[[columnname]]
  column_na <- crimes_table_subset_num_na[[columnname]]
  hist(column,   
       main = columnname,
       xlab = get_label(column)
          )
  hist(column_na,   
       main = paste(columnname, "(missing data)"),
       xlab = get_label(column)
          )
}
```

# Multivariate descriptives

After investigating the univariate descriptives, multivariate descriptives are calculated.

The correlation matrix shows the extent to which the variables in the dataset are correlated with each other.
Below, all variables are listed, sorted from highest to lowest correlation with the outcome variable.

- *racepctblack* ($r = 0.63$)
- *PctPopUnderPov* ($r = 0.51$)
- *PctNotHSGrad* ($r = 0.47$)
- *PctLess9thGrade* ($r = 0.37$)
- *PctEmploy* ($r = -0.32$)
- *perCapInc* ($r = -0.32$)
- *PctBSorMore* ($r = 0.3$)
- *PctImmig* ($r = 0.19$)
- *agePct12t29* ($r = 0.11$)

It's important to mention that these correlations are indicators of an association, not of a causation.

The following predictors are highly correlated with each other. Therefore, it is best not to include them together in a model later.

- *PctNotHSGrad* and *PctLess9thGrade* ($r = 0.93$)
- *perCapInc* and *PctBSorMore* ($r = 0.77$)
- *PctNotHSGrad* and *PctBSorMore* ($r = -0.75$)

However the choice for predictors for the model will be dealt with thoroughly during the model building.

It is noticeable that the variable *racepctblack* is the one most strongly correlated with the outcome variable ($r = 0.63$), even more than *PctPopUnderPov*, the head predictor that was chosen for this research.

It is noticable the the variables *PctImmig* and *PctPopUnderPov* have correlation coefficients that are really low. *PctImmig* would therefore not be a suitable parameter in a univariate model. Nevertheless, it will be included in the model building process. Especially in models with interaction effects, *PctImmig* may still be a useful predictor

```{r correlations}
cor_matrix <- cor(crimes_table_subset_num[,-'population'])
cor_values <- as.data.frame(as.table(cor_matrix))

library(ggcorrplot)
ggcorrplot(cor_matrix, lab = TRUE, type = "lower", 
           lab_size = 3, colors = c("red", "white", "blue"))

```
The following scatter plots were generated:

- for each variable, a scatter plot showing the relationship with the outcome variable *ViolentCrimesPerPop*;
- for each variable, a scatter plot showing the relationship with the main predictor variable *PctPopUnderPov*.

The first series of scatter plots indicates that not all variables have a linear relationship with *ViolentCrimesPerPop*.
In particular, the following variables do not appear to exhibit a clear linear trend:

- *perCapInc*
- *agePct12t29* (which also had a very low correlation coefficient)

Other variables show a somewhat linear pattern, although this trend is often distorted in the extreme regions of the x-axis.

The second series of scatter plots suggests that some variables exhibit a linear relationship with the main predictor *PctPopUnderPov*.
In particular, the following variables appear to show a fairly linear trend:

- *PctEmploy*
- *PctLess9thGrade*
- *PctNotHSGrad*

This implies that these variables are probably not suitable as additional predictors when *PctPopUnderPov* is already included in the model as this may cause multicollinearity.

```{r scatter plots, fig.width=8, fig.height=12}
x_vars <- colnames(crimes_table_subset_num)
dict_labels <- setNames(sapply(x_vars, function(x_var) get_label(crimes_table_subset_num[[x_var]])), x_vars)

library(ggplot2)
library(patchwork)
df <- crimes_table_subset_num[,-c("population")]
y_var <- "ViolentCrimesPerPop"
x_vars <- setdiff(colnames(df), y_var)
plots <- lapply(x_vars, function(x_var) {
    ggplot(df, aes_string(x_var,y_var)) +
    geom_point(alpha = 0.6, size = 0.7) +
    geom_smooth(method = "lm", color = "blue", se = FALSE)+
    geom_smooth(method = "loess", color = "red", se = FALSE)+
    theme_bw(base_size = 8) +
    labs(x = str_wrap(paste(x_var, " (", dict_labels[x_var], ")", sep = ""), width = 45))
}
)
# Print 9 plots per pg
print(wrap_plots(plots, ncol = 3))

df <- crimes_table_subset_num[,-c("population", "ViolentCrimesPerPop")]
y_var <- "PctPopUnderPov"
x_vars <- setdiff(colnames(df), y_var)
plots <- lapply(x_vars, function(x_var) {
    ggplot(df, aes_string(x_var,y_var))+
    geom_point(alpha = 0.6, size = 0.7) +
    geom_smooth(method = "lm", color = "blue", se = FALSE)+
    geom_smooth(method = "loess", color = "red", se = FALSE)+
    theme_bw(base_size = 8) +
    labs(x = str_wrap(paste(x_var, " (", dict_labels[x_var], ")", sep = ""), width = 45))
}
)

# Print 9 plots per pg
print(wrap_plots(plots, ncol = 3))
```


The scatter plots reveal one outlier for the *ViolentCrimesPerPop* variable. This outlier is the community Chestercity. For now the datapoint is kept for further analysis. In the diagnostics section, we will further investigate which data points can be considered outliers and what their influence is on the model.

```{r outlier}
crimes_table_subset[order(crimes_table_subset_num$ViolentCrimesPerPop, decreasing=TRUE), , drop = FALSE]
```


In the protocol it's stated that small communities may have a higher probability to have more extreme values of the predictor and response variables. To investigate this scatter plots are created with log(*population*) as x variable. It is clear that communities with a very small population show a very large spread for all variables.

```{r scatter plots population, fig.width=8, fig.height=12}
crimes_table_subset_num$logpopulation <- lapply(crimes_table_subset_num$population, log10)
crimes_table_subset_num$logpopulation <- log10(crimes_table_subset_num$population)
df <- crimes_table_subset_num
x_var <- "logpopulation"
y_vars <- setdiff(colnames(df), x_var)
plots <- lapply(y_vars, function(y_var) {
    ggplot(df, aes_string(x_var,y_var))+
    geom_point(alpha = 0.6, size = 0.7) +
    geom_smooth(method = "lm", color = "blue", se = FALSE)+
    geom_smooth(method = "loess", color = "red", se = FALSE)+
    theme_bw(base_size = 8) +
    labs(x = "log(population)", y = str_wrap(y_var, width = 45))
}
)

# Print 9 plots per pg
print(wrap_plots(plots, ncol = 3))

```

# Model Building

Before performing linear regression and building models, the dataset is randomly split into a training set (80% of the data) and a holdout set (20% of the data). This holdout set will be used to validate the final model.

```{r dataset split}
set.seed(987654321)
n <- nrow(crimes_table_subset_num)
training <- sample(1:n, size = floor(0.8 * n))
train_data <- crimes_table_subset_num[training, ]
test_data <- crimes_table_subset_num[-training, ]
n_training <- nrow(train_data)

cat("Training set size:", n_training, "\n")
cat("Test set size:", nrow(test_data), "\n")
```

## Univariate linear regression

 The simple univariate regression equation we estimate with the training set is given as follows:

$$
ViolentCrimesPerPop_i = \beta_0 + \beta_1 \cdot PctPopUnderPov_i + \epsilon_i
$$

```{r Univariate regression}
fit_simple <- lm(ViolentCrimesPerPop ~ PctPopUnderPov, data = train_data)
summary(fit_simple)
```
We show the relevant statistics to be discussed in this section:
```{r Extract relevant statistics}

cat("Regression equation: ViolentCrimesPerPop =", 
    round(coef(fit_simple)[1], 2), "+", 
    round(coef(fit_simple)[2], 2), "* PctPopUnderPov\n\n")

# R-squared and BIC-value
cat("R-squared:", round(summary(fit_simple)$r.squared, 4), "\n")
cat("Adjusted R-squared:", round(summary(fit_simple)$adj.r.squared, 4), "\n")
cat("BIC:", BIC(fit_simple), "\n")

# MSE
sse_simple <- sum(fit_simple$residuals^2) 
mse_simple <- sse_simple/(n_training - 2) 
cat("SSE:", round(sse_simple, 2), "\n")
# Calculation of BIC-waarde in R: -2 * as.numeric(logLik(fit)) + attr(logLik(fit), "df") * log(n)
# Not the one from the course slides n*log(sse_simple) - n*log(n) + p*log(n), but ok?
cat("MSE:", round(mse_simple, 2), "\n")

# Confidence intervals for coefficients
cat("\n95% Confidence Intervals:\n")
print(confint(fit_simple))

# ANOVA
anova(fit_simple)
```

*PctPopUnderPov* = <mean> increase in violent crimes per 100K population if poverty rate increases by one percentage point

### Assumption checks

We check assumptions linearity, independence of errors, homoscedasticity, and normality of errors. It is clear these assumptions are violated. Larger outcome values tend to be underestimated, the variance for larger outcome values is larger and the QQ-plot shows violation of the normality assumption. In the next step, we extend the model by adding relevant predictors and reassess the assumptions.

```{r simple-lm-diagnostics, fig.width=10, fig.height=8}
par(mfrow = c(2, 2))

#Residuals vs Fitted 
plot(fit_simple$fitted.values, fit_simple$residuals,
     xlab = "Fitted values", ylab = "Residuals",
     main = "Residuals vs Fitted")
abline(h = 0, col = "red", lty = 2)
lines(lowess(fit_simple$fitted.values, fit_simple$residuals), col = "blue")

# Squared residuals vs Fitted
plot(fit_simple$fitted.values, fit_simple$residuals^2,
     xlab = "Fitted values", ylab = "Squared Residuals",
     main = "Squared Residuals vs Fitted")
lines(lowess(fit_simple$fitted.values, fit_simple$residuals^2), col = "blue")

# QQ-plot of residuals (normality)
qqnorm(fit_simple$residuals, main = "Normal Q-Q Plot of Residuals")
qqline(fit_simple$residuals, col = "red")
 
# Studentized residuals
stud_res <- rstudent(fit_simple)
plot(fit_simple$fitted.values, stud_res,
     xlab = "Fitted values", ylab = "Studentized Residuals",
     main = "Studentized Residuals vs Fitted")
outliers_simple <- which(abs(stud_res) > 2)
```

Table to get a visual illustration of whether outliers are more common in small pop
```{r outliers vs population1}
par(mfrow = c(1, 2))
# Residuals vs population
plot(train_data$logpopulation, fit_simple$residuals,
     xlab = "log(population)", ylab = "Residuals")
abline(h = 0, col = "red", lty = 2)
lines(lowess(train_data$logpopulation, fit_simple$residuals), col = "blue")

plot(train_data$logpopulation, stud_res,
     xlab = "log(population)", ylab = "Studentized Residuals")
abline(h = 0, col = "red", lty = 2)
lines(lowess(train_data$logpopulation, stud_res), col = "blue")
par(mfrow = c(1, 1))
```

## Model selection

We use an all-possible regressions procedure to select predictor variables. We include models with a maximum of 5 predictor variables and only models with 0, 1, or 2 education predictor variables and without interactions. The best model is chosen based on the Bayesian Information Criterion.

```{r model selection, message=FALSE}

max_extra_predictors <- 4
# Define predictor variables for model selection
predictors <- c("perCapInc", "PctEmploy", 
                "PctLess9thGrade", "PctNotHSGrad", "PctBSorMore",
                "racepctblack", "agePct12t29", "PctImmig")

# Educ variables
educ <- c("PctLess9thGrade", "PctNotHSGrad", "PctBSorMore")

formulas <- list()
for (i in 1:max_extra_predictors) {
  tmp <- combn(predictors, i)
  tmp <- apply(tmp, 2, paste, collapse=" + ")
  tmp <- paste0("ViolentCrimesPerPop~PctPopUnderPov + ", tmp)
  formulas[[i]] <- tmp
}
formulas <- unlist(formulas)
formulas <- sapply(formulas, as.formula)
models <- lapply(formulas, lm, data=train_data)

bics <- sapply(models, BIC)
r_square <- sapply(models, function(m) summary(m)$r.squared)
adj_r_square <- sapply(models, function(m) summary(m)$adj.r.squared)
formula_vector <- vapply(formulas, function(f) paste(deparse(f), collapse = ""), character(1))

# build the frame
model_ranking <- data.frame(
  formula = formula_vector,
  r.square = r_square,
  adj.r.square = adj_r_square,
  BIC = bics
)
model_ranking <- model_ranking[order(model_ranking$BIC), ]
```

The best model according to the procedure is:
$$
ViolentCrimesPerPop_i = \beta_0 + \beta_1 \cdot PctPopUnderPov_i + \beta_2 \cdot PctLess9thGrade_i + \beta_3 \cdot PctNotHSGrad_i + \beta_4 \cdot PctImmig_i + \epsilon_i
$$

```{r show best model}
# Print best model
best <- which.min(model_ranking$BIC)
best_pred <- model_ranking$formula[best]
cat("\nBest model:\n")
cat(best_pred, "\n")
cat("BIC:", round(model_ranking$BIC[best], 2), "\n")
cat("Adjusted R²:", round(model_ranking$adj.r.square[best], 4), "\n")

fit_multi <- lm(best_pred, data = train_data)
multi_var_summary <- summary(fit_multi)
multi_var_summary
```

### Partial Regression Plots
The partial regression plots show that, with respect to the effects of the predictor variables, no clear deviation from linearity is visible. There is no transformation of the predictor variables recommended.

```{r partial-regression-plots, fig.width=10, fig.height=8}
predictor_list <- row.names(multi_var_summary$coefficients[-1,])

partial_regression_plot <- function(data, outcome, predictor, predictor_list) {
  temp <- train_data
  controls <- setdiff(predictor_list, predictor)
  
  formula_outcome  <- as.formula(paste(outcome, "~", paste(controls, collapse = " + ")))
  formula_pred <- as.formula(paste(predictor, "~", paste(controls, collapse = " + ")))
  
  lm_outcome <- lm(formula_outcome, data = temp)
  temp$resid_outcome <- resid(lm_outcome)
  lm_pred <- lm(formula_pred, data = temp)
  temp$resid_pred <- resid(lm_pred)

ggplot(temp, aes(x = resid_pred, y = resid_outcome)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  geom_smooth(method = "loess", se = FALSE) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  labs(x = paste("Residuals ", predictor, " ~ controls", sep = ""), y = paste("Residuals ", outcome, " ~ controls", sep = ""))
}

plots <- lapply(predictor_list, function(predictor) {
    partial_regression_plot(train_data, "ViolentCrimesPerPop", predictor, predictor_list)
}
)

# Print 9 plots per pg
print(wrap_plots(plots, ncol = 3))

```

### Assumption checks selected model
We see that the assumptions of normality and equal error variances of the error terms are again violated in the original multivariate model. 
```{r final model-diagnostics, fig.width=10, fig.height=8}
par(mfrow = c(2, 2))

#Residuals vs Fitted
plot(fit_multi$fitted.values, fit_multi$residuals,
     xlab = "Fitted values", ylab = "Residuals",
     main = "Residuals vs Fitted (Final Model)")
abline(h = 0, col = "red", lty = 2)
lines(lowess(fit_multi$fitted.values, fit_multi$residuals), col = "blue")

# Squared residuals vs Fitted
plot(fit_multi$fitted.values, fit_multi$residuals^2,
     xlab = "Fitted values", ylab = "Squared Residuals",
     main = "Squared Residuals vs Fitted")
lines(lowess(fit_multi$fitted.values, fit_multi$residuals^2), col = "blue")

# QQ-plot
qqnorm(fit_multi$residuals, main = "Normal Q-Q Plot (Final Model)")
qqline(fit_multi$residuals, col = "red")

# Studentized residuals
stud_res_multi <- rstudent(fit_multi)
plot(fit_multi$fitted.values, stud_res_multi,
     xlab = "Fitted values", ylab = "Studentized Residuals",
     main = "Studentized Residuals vs Fitted")
abline(h = 0, col = "red", lty = 2)
lines(lowess(fit_multi$fitted.values, stud_res_multi), col = "blue")

par(mfrow = c(1, 1))
```
A possible solution is to apply a log transformation of Y. The result shows approximate constant variances and residuals reasonably close to normal, applying the log transformation therefore offers a substantial improvement of our model. The reduction in R-squared suggests that the model-fit was inflated due to heteroscedasticity.  We still see slightly heavy tails. 

```{r}
fit_log <- lm(log(ViolentCrimesPerPop + 1) ~ 
                PctPopUnderPov + PctBSorMore + racepctblack + 
                PctImmig + PctPopUnderPov:PctBSorMore,
              data = train_data)

summary(fit_log)
plot(fit_log)
par(mfrow = c(1, 1))
```
## Rerun selection after transformation of Y
We will repeat the model building process with the log-transformed ViolentCrimesPerPop.

```{r adding column with log transform}
train_data$logViolent <- log(train_data$ViolentCrimesPerPop + 1)
```

## Model selection

We use an all-possible regressions procedure to select predictor variables. We include models with a maximum of 5 predictor variables and only models with 0, 1, or 2 education predictor variables. The best model is chosen based on the Bayesian Information Criterion.

```{r model selection2, message=FALSE}

max_extra_predictors <- 4
# Define predictor variables for model selection
predictors <- c("perCapInc", "PctEmploy", 
                "PctLess9thGrade", "PctNotHSGrad", "PctBSorMore",
                "racepctblack", "agePct12t29", "PctImmig")

# Educ variables
educ <- c("PctLess9thGrade", "PctNotHSGrad", "PctBSorMore")

formulas <- list()
for (i in 1:max_extra_predictors) {
  tmp <- combn(predictors, i)
  tmp <- apply(tmp, 2, paste, collapse=" + ")
  tmp <- paste0("logViolent~PctPopUnderPov + ", tmp)
  formulas[[i]] <- tmp
}
formulas <- unlist(formulas)
formulas <- sapply(formulas, as.formula)
models <- lapply(formulas, lm, data=train_data)

bics <- sapply(models, BIC)
r_square <- sapply(models, function(m) summary(m)$r.squared)
adj_r_square <- sapply(models, function(m) summary(m)$adj.r.squared)
formula_vector <- vapply(formulas, function(f) paste(deparse(f), collapse = ""), character(1))

# build the frame
model_ranking <- data.frame(
  formula = formula_vector,
  r.square = r_square,
  adj.r.square = adj_r_square,
  BIC = bics
)
model_ranking <- model_ranking[order(model_ranking$BIC), ]
```

We then run the multivariate regression equation

```{r show best model 2}
# Print best model
best <- which.min(model_ranking$BIC)
best_pred <- model_ranking$formula[best]
cat("\nBest model:\n")
cat(best_pred, "\n")
cat("BIC:", round(model_ranking$BIC[best], 2), "\n")
cat("Adjusted R²:", round(model_ranking$adj.r.square[best], 4), "\n")

fit_multi <- lm(best_pred, data = train_data)
multi_var_summary <- summary(fit_multi)
multi_var_summary
```

### Partial Regression Plots
Again the partial regression plots show that, with respect to the effects of the predictor variables, no clear deviation from linearity is visible. There is no transformation of the predictor variables recommended.
```{r partial-regression-plots2, fig.width=10, fig.height=8}
predictor_list <- row.names(multi_var_summary$coefficients[-1,])
plots <- lapply(predictor_list, function(predictor) {
    partial_regression_plot(train_data, "ViolentCrimesPerPop", predictor, predictor_list)
}
)

# Print 9 plots per pg
print(wrap_plots(plots, ncol = 3))
```

### Interaction Terms Selection

Following the protocol, we add all interaction terms of the predictor variables with our main predictor variable *PctPopUnderPov* and evaluate their significance.

```{r interaction term selection 2}
selected_vars <- row.names(multi_var_summary$coefficients[-(1:2),])
interaction_terms <- paste("PctPopUnderPov", selected_vars, sep = ":")
 
formulas <- sapply(interaction_terms, function(i) {
  paste0(best_pred, " + ", i)
})

formulas <- lapply(formulas, as.formula)
models <- lapply(formulas, lm, data=train_data)

interaction_models_form <- vapply(formulas, function(f) 
  paste(deparse(f), collapse = ""), character(1))
summary_val_extraction <- function(x, item) {
  tmp <- summary(x)$coefficients
  tmp[nrow(tmp), item]
}
p_vals_interaction <- sapply(models, function(m) 
  summary_val_extraction(m, "Pr(>|t|)"))
t_vals_interaction <- sapply(models, function(m) 
  summary_val_extraction(m, "t value"))

bics <- sapply(models, BIC)
r_square <- sapply(models, function(m) summary(m)$r.squared)
adj_r_square <- sapply(models, function(m) summary(m)$adj.r.squared)
delta_adj_r_square <- sapply(models, function(m) 
  summary(m)$adj.r.squared - summary(fit_multi)$adj.r.squared)

interaction_table <- data.frame(
  p.vals = p_vals_interaction,
  t.vals = t_vals_interaction,
  r.square = r_square,
  adj.r.square = adj_r_square,
  delta.adj = delta_adj_r_square,
  BIC = bics
)
interaction_table <- interaction_table[order(interaction_table$p.vals), ]
interaction_table
  
best_interaction <- row.names(interaction_table[1,])
```

## Multivariate Model

The model selection procedure shows that several interaction terms may add value to the model. Therefore, the model including all interaction terms between the covariates and *PctPopUnderPov* is tested.

```{r final model2}
# Estimate model with interaction
formula_final <- as.formula(paste("logViolent ~", 
                                  paste(predictor_list, collapse = " + "), "+",
                                  "PctPopUnderPov:racepctblack + PctPopUnderPov:PctLess9thGrade + PctPopUnderPov:PctImmig + PctPopUnderPov:PctBSorMore"))
fit_final <- lm(formula_final, data = train_data)
summary(fit_final)
```
In this model the interaction *PctPopUnderPov:PctImmig* is the only one that is not significant. When this interaction term is deleted from the model, all interaction terms are significant. The final model:
$$
log(ViolentCrimesPerPop_i + 1) = \beta_0 + \beta_1 \cdot PctPopUnderPov_i + \beta_2 \cdot PctLess9thGrade_i + \beta_3 \cdot PctBSorMore_i + \beta_4 \cdot racepctblack _i + \beta_5 \cdot PctImmig_i + \beta_6 \cdot PctPopUnderPov_i \cdot racepctblack_i + \beta_7 \cdot PctPopUnderPov_i \cdot PctLess9thGrade_i + \beta_8 \cdot PctPopUnderPov_i \cdot PctBSorMore_i + \epsilon_i
$$
It is noticeable that the interaction terms that show a significant effect in a model with only one interaction term are not the same as the interaction terms that are significant in a model containing all four interaction terms. This is because the significance of predictor variables and interactions in a model also depends on which other predictors and interactions are included in the model.

```{r final model3}
# Estimate model with interaction
formula_final <- as.formula(paste("logViolent ~", 
                                  paste(predictor_list, collapse = " + "), "+",
                                  "PctPopUnderPov:racepctblack + PctPopUnderPov:PctLess9thGrade + PctPopUnderPov:PctBSorMore"))

fit_final <- lm(formula_final, data = train_data)
summary(fit_final)

# confint
print(confint(fit_final))
```

### Multicollinearity Check

Before checking model assumptions, we first assess multicollinearity using the Variance Inflation Factor (VIF) and remove a variable if necessary. 
```{r multicoll check2}
library(car)
# practicum: car::vif(fit)
vif <- vif(fit_final)
print(vif)
```
PctLess9thGrade was removed due to high multicollinearity. Removing it improves model stability and interpretability.

```{r removing multicoll}

# Estimate model with interaction
formula_final <- as.formula(paste("logViolent ~", 
                                  paste(predictor_list[-2], collapse = " + "), "+",
                                  "PctPopUnderPov:racepctblack  + PctPopUnderPov:PctBSorMore"))

fit_final <- lm(formula_final, data = train_data)
summary(fit_final)

```

We see that our model performs only a little less well, but this way we did account for multicollinearity and our estimates are correct. After removing PctLess9thGrade and therefore its interaction term, we see that the interaction between PctPopUnderPov:PctBSorMore is not longer significant and therefore also removed from the model. After adjusting for multicollinearity we see an expected small drop in R-squared, but the model still explains a substantial proportion of the variation in log violent crimes. 

```{r removing multicoll}

# Estimate model with interaction
formula_final <- as.formula(paste("logViolent ~", 
                                  paste(predictor_list[-2], collapse = " + "), "+",
                                  "PctPopUnderPov:racepctblack"))

fit_final <- lm(formula_final, data = train_data)
summary(fit_final)

```

```{r compare2}
# Compare models
cat("Comparison of models:\n")
cat("Original model adjusted R²: ", round(summary(fit_multi)$adj.r.squared, 4), "\n")
cat("interaction term model adjusted R²:  ", round(summary(fit_final)$adj.r.squared, 4), "\n")

```

### Assumption checks final model

```{r final-model-diagnostics, fig.width=10, fig.height=8}
par(mfrow = c(2, 2))

#Residuals vs Fitted
plot(fit_final$fitted.values, fit_final$residuals,
     xlab = "Fitted values", ylab = "Residuals",
     main = "Residuals vs Fitted (Final Model)")
abline(h = 0, col = "red", lty = 2)
lines(lowess(fit_final$fitted.values, fit_final$residuals), col = "blue")

# Squared residuals vs Fitted
plot(fit_final$fitted.values, fit_final$residuals^2,
     xlab = "Fitted values", ylab = "Squared Residuals",
     main = "Squared Residuals vs Fitted")
lines(lowess(fit_final$fitted.values, fit_final$residuals^2), col = "blue")

# QQ-plot
qqnorm(fit_final$residuals, main = "Normal Q-Q Plot (Final Model)")
qqline(fit_final$residuals, col = "red")

# Studentized residuals
stud_res_final <- rstudent(fit_final)
plot(fit_final$fitted.values, stud_res_final,
     xlab = "Fitted values", ylab = "Studentized Residuals",
     main = "Studentized Residuals vs Fitted")
abline(h = 0, col = "red", lty = 2)
lines(lowess(fit_final$fitted.values, stud_res_final), col = "blue")

```


```{r outliers vs population2}
par(mfrow = c(1, 2))
# Residuals vs population
plot(train_data$logpopulation, fit_final$residuals,
     xlab = "log(population)", ylab = "Residuals")
abline(h = 0, col = "red", lty = 2)
lines(lowess(train_data$logpopulation, fit_final$residuals), col = "blue")

plot(train_data$logpopulation, stud_res_final,
     xlab = "log(population)", ylab = "Studentized Residuals")
abline(h = 0, col = "red", lty = 2)
lines(lowess(train_data$logpopulation, stud_res_final), col = "blue")

par(mfrow = c(1, 1))
```

## Model diagnostics

De plotjes voor dit gedeelte beperken tot de nuttige en die ook bespreken. hierin kan je goed zien dat er toch redelijk wat influential outliers zijn, dus dat robust wel is.

```{r}
library(olsrr)
diagplots <- olsrr::ols_plot_diagnostics(fit_final, print_plot = TRUE)
```

Diagnostic plots (figuur) reveal several potential outliers and high-leverage points. To assess the impact of these points, we fit a robust regression using Bisquare weights. 

```{r robust-inference}
library(sandwich)
library(lmtest)
library(MASS)

robust <- rlm(formula(fit_final), data = train_data, psi = psi.bisquare)
summary(robust, method = "XtX")
```

```{r}
par(mfrow=c(2,2))
plot(fit_log)
par(mfrow=c(2,2))
plot(robust, which = 1)

qqnorm(resid(robust))
qqline(resid(robust))

```

A comparison of the coefficients reveal no substantial differences, indicating that the influential points are not the result of gross errors. <hier moeten nog extra checks van influence on inferences bij>.
The identified leverage-points can be called 'good leverages' as they exhibit high leverage but their residuals are still small, this even improves the precision of the regression coefficients. (zie referentie) It'

```{r influence inference}
# Compare OLS vs Robust coefficients
comparison <- data.frame(
  OLS = coef(fit_final),
  Robust = coef(robust),
  Difference = coef(fit_final) - coef(robust)
)

print(round(comparison, 4))
```


### Outlier and Influence Diagnostics 

We use several diagnostic measures to identify influential observations

```{r influence diagnostics}
# Calculate diagnostics
stud_res_final <- rstudent(fit_final)
leverage <- hatvalues(fit_final)
p <- length(coef(fit_final))
n_train <- nrow(train_data)
leverage_threshold <- 2 * p / n_train
cooks_d <- cooks.distance(fit_final)
dffits_val <- dffits(fit_final)
dffits_threshold <- 2 * sqrt(p / n_train)
dfbetas_val <- dfbetas(fit_final)
dfbetas_threshold <- 2 / sqrt(n_train)

# dataframe
diagnostics <- data.frame(
  obs = 1:n_train,
  population = train_data$population,
  # zowel studentized deleted residuals als studentized residuals insteken?
  # DFBETAS ook insteken (per beta kan je dat bepalen) (chapter 10 Diagnostics slide 40)
  stud_residual = stud_res_final,
  leverage = leverage,
  cooks_d = cooks_d,
  dffits = dffits_val
)

# Flag observations
diagnostics$outlier_residual <- abs(diagnostics$stud_residual) > 2
diagnostics$high_leverage <- diagnostics$leverage > leverage_threshold
diagnostics$high_cooks <- diagnostics$cooks_d > 4 / n_train
diagnostics$high_dffits <- abs(diagnostics$dffits) > dffits_threshold

# summ
cat("Outliers by studentized residuals (|r*| > 2):", sum(diagnostics$outlier_residual), "\n")
cat("High leverage observations (h >", round(leverage_threshold, 4), "):", 
    sum(diagnostics$high_leverage), "\n")
cat("High Cook's distance (D >", round(4/n_train, 4), "):", 
    sum(diagnostics$high_cooks), "\n")
cat("High DFFITS (|DFFITS| >", round(dffits_threshold, 4), "):", 
    sum(diagnostics$high_dffits), "\n")
```

```{r influential observations}
# find influent obs
influential <- diagnostics[diagnostics$high_cooks | diagnostics$high_dffits, ]
influential <- influential[order(-influential$cooks_d), ]
print(head(influential[, c("obs", "population", "stud_residual", "leverage", "cooks_d", "dffits")], 10))
```

```{r influence plot, fig.width=8, fig.height=6}
# Influence plot
plot(leverage, stud_res_final, 
     xlab = "Leverage", ylab = "Studentized Residuals",
     main = "Influence Plot",
     cex = sqrt(cooks_d) * 10)
```

```{r dfbetas plots, fig.width=10, fig.height=8}
# DFBETAS plots
par(mfrow = c(2, ceiling(ncol(dfbetas_val)/2)))
for(j in 1:ncol(dfbetas_val)) {
  plot(dfbetas_val[, j], 
       ylab = paste("DFBETAS -", colnames(dfbetas_val)[j]),
       main = colnames(dfbetas_val)[j])
}
par(mfrow = c(1, 1))
```



## interpretation final model

Our final model is:`r formula_final`.
```{r}
summary(fit_final)
print(confint(fit_final))
```

```{r}
library(stdmod)
b <- coef(fit_final)
mean_race <- mean(train_data$racepctblack)
mean_9thgrade <- mean(train_data$PctLess9thGrade)
mean_bsormore <- mean(train_data$PctBSorMore)
mean_poverty <- mean(train_data$PctPopUnderPov)

coef_mean <- b["PctPopUnderPov"] +
      b["PctPopUnderPov:racepctblack"]    * mean_race +
      b["PctPopUnderPov:PctLess9thGrade"] * mean_9thgrade +
      b["PctPopUnderPov:PctBSorMore"]     * mean_bsormore
percentage_change <- (exp(coef_mean) - 1) *100
```

#### notes on interpretation

Our final model is a log-linear model, this makes interpretation of the coefficients less intuitive. We will start by giving the coefficients that express the estimated change in the log of the expected violent crime rate per 100k population with an increase of the predictor variable by 1 unit. To ease interpretation we will back transform this coefficient and multiply it by 100 to express the estimated percentage change of the mean violent crime rate / 100k when the predictor variable is increased by 1 unit. The intercept on its own is not interpretable as it would require all predictor variables (and interaction terms) to be zero. This is not in the scope of our model. If it were, the intercept of `r b["(intercept)"]` could be interpreted as the estimated log of expected crime rate when all predictor variables are 0.
There is no use in interpreting interaction-term coefficients on their own, as they indicate the effect of one predictor on the other, but have no direct effect on its own.


#### interpretation of PctPopUnderPov


The effect of PctPopUnderPov varies with racepctblack, PctLess9thGrade and PctBsorMore through the interaction terms. This means that the effect of PctPopUnderPov is not simply given by its coefficient, but instead we can look at the estimated effect of PctPopUnderPov on the log of expected violent crimes as `r summary(fit_final)$coefficients[2,1]` + `r summary(fit_final)$coefficients[7,1]` * racepctblack + `r  summary(fit_final)$coefficients[8,1]` * pctless9thgrade + `r summary(fit_final)$coeffecients[9,1]` * cptbsormore. Interpretation is more intuitive if we back transform the logdata. The effect of an increase in PctPopUnderPop with one unit (one percent) on violent crimes per 100k is then calculated by:  exp(`r b["PctPopUnderPov"]` + `r b["PctPopUnderPov:racepctblack"]` * racepctblack + `r b["PctPopUnderPov:PctLess9thGrade"]` * pctless9thgrade + `r b["PctPopUnderPov:PctBSorMore"]` * cptbsormore) -1 when all other variables are held constant. 
If we take for example the mean of the 3 interacting terms to calculate the effect of PctPoponderpov when the interacting variables are held at their average and we back transform it we can find `r exp(coef_mean) -1`.
We can interpret the estimated percentage change, `r percentage_change`%, as the estimated increase in expected value of violent crimes (per population of 100k) per percentage increase of pop under pov, when the interacting variables are held at their average and all other variables are held constant. 



#### interpretation of PctLess9thGrade

```{r}
set.seed(123)
CI_9thgrade <- cond_effect_boot(fit_final,
            x = "PctLess9thGrade", w = "PctPopUnderPov", nboot = 2000)
ci_lower <- exp(CI_9thgrade$"CI Lower"[CI_9thgrade$Level == "Medium"]) - 1 
ci_upper <- exp(CI_9thgrade$"CI Upper"[CI_9thgrade$Level == "Medium"]) - 1



```


As mentioned above, PctLess9thGrade and PctPopUnderPov interact. The effect of PctLess9thGrad is therefore impacted by the level of PctPopUnderPov: `r b["PctLess9thGrade"]` + `r b["PctPopUnderPov:PctLess9thGrade"]` * PctPopUnderPov. This interaction effect is reinforcing, meaning that an increase in PctPopUnderPov would lead to a more negative slope for PctLess9thGrade. Taking the mean of PctPopUnderPov the interaction-adjusted coefficient for Pctless9thegrade is `r b["PctLess9thGrade"] + b["PctPopUnderPov:PctLess9thGrade"] * mean_poverty`. Increasing Pctless9thGrade by one percent (one unit), we estimate that the expected value of violent crimes (per 100k) decreases by `r (exp(b["PctLess9thGrade"] + (b["PctPopUnderPov:PctLess9thGrade"] * mean_poverty)) -1) * 100`% (original scale) when PctPopUnderPov is held at its mean and all other variables are held constant. We can find a 95% confidence interval using cond_effect_boot() from package *stdmod* of [`r ci_lower` , `r ci_upper`]. We can therefore say that with a .95 confidence coefficient, we estimate that the percentage change of expected crime rates is somewhere between `r ci_lower * 100`% and `r ci_upper * 100`%. Note that this is a pointwise confidence interval for when PctPopUnderPov is held at its mean and all other variables are held constant. However we see that the coefficient of the main effect in the model is not significant, but still included because of the interaction term. We also see that the multicollinearity increases, this can increase standard errors and lead to unstable coefficient estimates. It therefore provides a possible explanation to the sign of the estimates that are incosistent with theoretical expectations.




#### interpretation of PctBSorMore

There is also an interaction term included between PctBSorMore and PctPopUnderPov. The interpretation is similar to that of PctLess9thGrade. The conditional effect on of PctBSorMore on the log expected violent crime rate is given by: `r b["PctBSorMore"]` + `r b["PctPopUnderPov:PctBSorMore"]`* PctPopUnderPov. Both coefficients are negative, indicating a reinforcing effect: increases in PctPopUnderPov enforces the negative effect of PctBSorMore. Similarly to before we can take the mean of PctPopUnderPov and estimate the conditional effect of PctBSorMore on the log expected value of crime rate per unit increase of PctBSorMore, when keeping poverty at its mean and all other variables constant: `r b["PctBSorMore"]` + `r b["PctPopUnderPov:PctBSorMore"] * mean_poverty`. Undoing the log transformation we get `r (exp(b["PctBSorMore"] + b["PctPopUnderPov:PctBSorMore"] * mean_poverty) - 1)* 100`%, which can be interpreted as the estimated percent change in expected crime rate by increasing PctBSorMore by one unit (1%), keeping PctPovUnderPop at its mean and all other variables constant. Thus if, under the conditions stated above, a higher percentage of the population has a Bachelors degree or higher, the estimated mean crime rate decreases and this effect is more pronounced for higher levels of PctUnderPov.
```{r}
set.seed(123)
cond_effect_boot(fit_final,
            x = "PctBSorMore", w = "PctPopUnderPov", nboot = 2000)
```



#### interpretation of racepctblack

We follow the same logic for racepctblack as for the previous 2. However we now see an interference interaction effect: the conditional effect of racepctblack is given by: `r b["racepctblack"]` + `r b["PctPopUnderPov:racepctblack"]` * PctPopUnderPov. If we look at the main effect of racepctblack (PctPopUnderPov = 0), we see a positive effect, where we see a negative contribution of the interaction term: the slope of the response function against racepctblack decreases for higher levels of PctPopUnderPov. For a higher percentage of people living under the poverty line, the estimated effect of percentage of black people on violent crime rates is lower than when there is a lower percentage of people living under the poverty line. If we look at the conditional effect of racepctblack when PctpovUnderPop is held at its mean we get: `r b["racepctblack"]` + `r b["PctPopUnderPov:PctBSorMore"] * mean_poverty`. Exponentiating this expression to return to the original scale we get an estimated percentage change of `r (exp(b["racepctblack"] +  b["PctPopUnderPov:racepctblack"] * mean_poverty)-1) *100`% of the expected crime rates (100k) by increasing the racepctblack by one unit (1%), keeping PctPovUnderPov at its mean and all other variables constant. Increasing levels of PctPovUnderPov would result in a smaller positive effect of racepctblack than lower levels of PctPopUnderPov.

```{r}
set.seed(123)

cond_effect_boot(fit_final,
            x = "racepctblack", w = "PctPopUnderPov", nboot = 2000)


```


#### interpretation of PctImmig 

PctImmig is not involved in any interaction term, therefore we can interpret the main effect `r b["PctImmig"]` on its own. Exponentiating and multiplying by 100 this coefficients we get: `r (exp(b["PctImmig"]) - 1)* 100`. The exponentiated 95% confidence interval is [`r exp(confint(fit_final)[6,1]) - 1` , `r exp(confint(fit_final)[6,2]) -1 `]. With confidence coefficient .95 we estimate that the percentage change in expected crime rates per 100k population per unit increase in PctImmig when keeping all other variables constant will be somewhere between `r (exp(confint(fit_final)[6,1]) - 1) * 100`% and `r (exp(confint(fit_final)[6,2]) -1) * 100`%.


## Summary
Dusja multivariate model stuk beter dan univariate model als je kijkt naar de tabel

```{r summary}
# summary

mse_final <- mean(fit_final$residuals^2)
summary_results <- data.frame(
  Model = c("Simple (PctPopUnderPov only)", "Final Multivariate"),
  R_squared = c(round(summary(fit)$r.squared, 4),
                      round(summary(fit_final)$r.squared, 4)),
  Adj_R_squared = c(round(summary(fit)$adj.r.squared, 4),
                          round(summary(fit_final)$adj.r.squared, 4)),
  MSE = c(round(mse_simple, 2), round(mse_final, 2))
)

kable(summary_results, caption = "Comparison of Simple and Final Multivariate Models")
```

## model validation
Using the holdout set, we compute the Mean Squared Prediction Error (MSPR) and comparing it to the Mean Squared Error (MSPR) when the model is used to predict data in the training set.


```{r model validation backtransformation}
# Predictions on test set
# Transforming outcome variable in test dataset
test_data$logViolent <- log(test_data$ViolentCrimesPerPop + 1)

# we backtransform the data to the normal scale
backtransformation <- function(value){
  exp(value) - 1
}
pred_interval_test_log <- predict(fit_final, newdata = test_data, interval = "prediction", level = 0.95)
pred_interval_train_log <- predict(fit_final, newdata = train_data, interval = "prediction", level = 0.95)
pred_interval_test <- apply(pred_interval_test_log, 1:2, backtransformation)
pred_interval_train <- apply(pred_interval_train_log, 1:2, backtransformation)
pred_interval_test_simple <- predict(fit_simple, newdata = test_data, interval = "prediction", level = 0.95)
pred_interval_train_simple <- predict(fit_simple, newdata = train_data, interval = "prediction", level = 0.95)

#mspr_training_log <- sum((train_data$logViolent - pred_interval_train_log[, "fit"])^2)/(n_training - 9)
```

As expected, 95% of the data points fall within the 95% prediction intervals. However, the prediction intervals are far too wide, making the predictions difficult to use.
```{r model validation prediction interval}
inside <- test_data$ViolentCrimesPerPop >= pred_interval_test[, "lwr"] & test_data$ViolentCrimesPerPop <= pred_interval_test[, "upr"]
cat("Fraction of datapoints in prediction interval:", mean(inside), "\n")

hist(pred_interval_test[, "upr"] - pred_interval_test[, "lwr"],
     main = "Width prediction interval",
     xlab = "Width prediction interval",
     xlim = c(0, 15000),
     breaks = 50)
```
```{r model plots}
# prediction intervals test data
df_prediction_test <- data.frame(observed = test_data$ViolentCrimesPerPop, predicted = pred_interval_test[, "fit"])

ggplot(df_prediction_test, aes(observed, predicted))+
  geom_point()+
  geom_smooth(se = FALSE)+
  geom_abline(intercept = 0, slope = 1, color = "red")+
  theme_bw() +
  labs(x = "number of violent crimes per 100K population (observed)",
       y = "number of violent crimes per 100K population (predicted)",
       title = "Test dataset")

# prediction intervals training data
df_prediction_train <- data.frame(observed = train_data$ViolentCrimesPerPop, predicted = pred_interval_train[, "fit"])

ggplot(df_prediction_train, aes(observed, predicted))+
  geom_point()+
  geom_smooth(se = FALSE)+
  geom_abline(intercept = 0, slope = 1, color = "red")+
  theme_bw() +
  labs(x = "number of violent crimes per 100K population (observed)",
       y = "number of violent crimes per 100K population (predicted)",
       title = "Train dataset")

# prediction intervals test data logscale
df_prediction_test_logscale <- data.frame(observed = test_data$logViolent, predicted = pred_interval_test_log[, "fit"])

ggplot(df_prediction_test_logscale, aes(observed, predicted))+
  geom_point()+
  geom_smooth(se = FALSE)+
  geom_abline(intercept = 0, slope = 1, color = "red")+
  theme_bw() +
  labs(x = "number of violent crimes per 100K population (observed)",
       y = "number of violent crimes per 100K population (predicted)",
       title = "Test dataset (log scale)")

# prediction intervals training data logscale
df_prediction_train_logscale <- data.frame(observed = train_data$logViolent, predicted = pred_interval_train_log[, "fit"])

ggplot(df_prediction_train_logscale, aes(observed, predicted))+
  geom_point()+
  geom_smooth(se = FALSE)+
  geom_abline(intercept = 0, slope = 1, color = "red")+
  theme_bw() +
  labs(x = "number of violent crimes per 100K population (observed)",
       y = "number of violent crimes per 100K population (predicted)",
       title = "Train dataset (log scale)")

# prediction intervals test data simple
df_prediction_test_simple <- data.frame(observed = test_data$ViolentCrimesPerPop, predicted = pred_interval_test_simple[, "fit"])

ggplot(df_prediction_test_simple, aes(observed, predicted))+
  geom_point()+
  geom_smooth(se = FALSE)+
  geom_abline(intercept = 0, slope = 1, color = "red")+
  theme_bw() +
  labs(x = "number of violent crimes per 100K population (observed)",
       y = "number of violent crimes per 100K population (predicted)",
       title = "Test dataset (univariate)")

# prediction intervals training data simple
df_prediction_train_simple <- data.frame(observed = train_data$ViolentCrimesPerPop, predicted = pred_interval_train_simple[, "fit"])

ggplot(df_prediction_train_simple, aes(observed, predicted))+
  geom_point()+
  geom_smooth(se = FALSE)+
  geom_abline(intercept = 0, slope = 1, color = "red")+
  theme_bw() +
  labs(x = "number of violent crimes per 100K population (observed)",
       y = "number of violent crimes per 100K population (predicted)",
       title = "Train dataset (univariate)")
```

```{r model validation MSPR and Rsquared, fig.width=8, fig.height=6}
# MSPR for test data
#mspr_test <- mean((test_data$ViolentCrimesPerPop - pred_interval_test[, "fit"])^2)
mspr_test <- mean((test_data$logViolent - pred_interval_test_log[, "fit"])^2)

# MSPR for training data
# mspr_train <- mean((train_data$ViolentCrimesPerPop - pred_interval_train[, "fit"])^2)
mspr_train <- mean((train_data$logViolent - pred_interval_train_log[, "fit"])^2)

cat("MSPR (training set):", round(mspr_train, 2), "\n")
cat("MSPR (test set):", round(mspr_test, 2), "\n")
cat("Ratio MSPR/MSE:", round(mspr_test/mspr_train, 4), "\n")

# R-squared on test data
#ss_res_test <- sum((test_data$ViolentCrimesPerPop - pred_interval_test[, "fit"])^2)
#ss_tot_test <- sum((test_data$ViolentCrimesPerPop - mean(test_data$ViolentCrimesPerPop))^2)
ss_res_test <- sum((test_data$logViolent - pred_interval_test_log[, "fit"])^2)
ss_tot_test <- sum((test_data$logViolent - mean(test_data$logViolent))^2)
r2_test <- 1 - ss_res_test/ss_tot_test
cat("R² on test set:", round(r2_test, 4), "\n")

# R-squared on training data
#ss_res_train <- sum((train_data$ViolentCrimesPerPop - pred_interval_train[, "fit"])^2)
#ss_tot_train <- sum((train_data$ViolentCrimesPerPop - mean(train_data$ViolentCrimesPerPop))^2)
ss_res_train <- sum((train_data$logViolent - pred_interval_train_log[, "fit"])^2)
ss_tot_train <- sum((train_data$logViolent - mean(train_data$logViolent))^2)
r2_train <- 1 - ss_res_train/ss_tot_train
cat("R² on training set:", round(r2_train, 4), "\n") 
```

```{r model validation MSPR and Rsquared simple, fig.width=8, fig.height=6}
# MSPR for test data
mspr_test_simple <- mean((test_data$ViolentCrimesPerPop - pred_interval_test_simple[, "fit"])^2)

# MSPR for training data
mspr_train_simple <- mean((train_data$ViolentCrimesPerPop - pred_interval_train_simple[, "fit"])^2)

cat("MSPR (training set):", round(mspr_train_simple, 2), "\n")
cat("MSPR (test set):", round(mspr_test_simple, 2), "\n")
cat("Ratio MSPR/MSE:", round(mspr_test_simple/mspr_train_simple, 4), "\n")

# R-squared on test data
ss_res_test_simple <- sum((test_data$ViolentCrimesPerPop - pred_interval_test_simple[, "fit"])^2)
ss_tot_test <- sum((test_data$ViolentCrimesPerPop - mean(test_data$ViolentCrimesPerPop))^2)
r2_test_simple <- 1 - ss_res_test_simple/ss_tot_test
cat("R² on test set:", round(r2_test_simple, 4), "\n")

# R-squared on training data
ss_res_train_simple <- sum((train_data$ViolentCrimesPerPop - pred_interval_train_simple[, "fit"])^2)
ss_tot_train <- sum((train_data$ViolentCrimesPerPop - mean(train_data$ViolentCrimesPerPop))^2)
r2_train_simple <- 1 - ss_res_train_simple/ss_tot_train
cat("R² on training set:", round(r2_train_simple, 4), "\n") 
```


Resultaten zijn niet zo goed, dus dit nog niet herwerkt.
```{r model validation and population size}
logpop_values <- seq(4.1, 6, 0.1)

mspr_fun <- function(logpop, data, fit_final){
  # filtering
  data_filtered <- data[data$logpopulation < logpop + 0.1 & data$logpopulation > logpop - 0.1, ]
  # Predictions on test set
  pred <- exp(predict(fit_final, newdata = data_filtered))
  mspr <- mean((data_filtered$ViolentCrimesPerPop - pred)^2)
}

mspr_values_test <- sapply(logpop_values, FUN=mspr_fun, data=test_data, fit_final=fit_final)
mspr_values_train <- sapply(logpop_values, FUN=mspr_fun, data=train_data, fit_final=fit_final)

df_plot_logpop_mspr <- data.frame(logpop = logpop_values, mspr_values_test, mspr_values_train)

ggplot(df_plot_logpop_mspr, aes_string(logpop_values,mspr_values_test)) +
    geom_point(alpha = 0.6, size = 1.7) +
    geom_smooth(method = "loess", color = "red", se = FALSE)+
    theme_bw(base_size = 8) +
    labs(title = "Mean squared prediction error for test data vs logpop", x = "logpop", y = "mspr")
ggplot(df_plot_logpop_mspr, aes_string(logpop_values,mspr_values_train)) +
    geom_point(alpha = 0.6, size = 1.7) +
    geom_smooth(method = "loess", color = "red", se = FALSE)+
    theme_bw(base_size = 8) +
    labs(title = "Mean squared prediction error for training data vs logpop", x = "logpop", y = "mspr")
```




# Statistical discussion

The used dataset is not random or representative of all US communities. The main missing data source is ViolentCrimesPerPop, where 221 observations are missing because of incomplete rape reporting in Midwestern States. As this variable is calculated as the sum of a few components, including rape, missing values could be not random and come from  state-specific reporting. This selective missingness could bias estimates if the these communities systematically differ in crime levels or demographic characteristics. Therefore, In the descriptives section, we tested whether the characteristics of the missing observations differed from those of the non-missing data, and we did not find any clear differences. Thus, we expect that the missing data do not have an important effect on our found results.

We hebben in the descriptives section wel getest of de karakteristieken van de missing data verschillend zijn tov de non missing data en we hebben geen duidelijke verschillen gevonden.

Second, the LEMAS survey includes all police departments with at least 100 officers and only a random sample of smaller ones. Because of this, large communities (and thus more urban communities) are overrepresented, but many small towns are not represented in the dataset. Thus, relationships found in the analysis should be interpreted at the city-level, and may be less likely to translate to the rural communities.

Another caveat is that the FBI’s data is from 1995, while the Census populations containing demographic variables are from 1990. This induces measurement error in the dependent variable. As the violent crime rate is calculated using 1995 population estimates in the denominator, the SE predictors are from 1990. Thus, communities that have a sizeable population growth or decline between 1990 and 1995 have very biased crime rates. Growing communities have understated rates, decline communities overstated rates.  Also, communities with larger population differences will have more noisy crime rate measurements (leading to heterosked?). This leads to measurement error in the dependent variable, leading to heterosked and outliers. (not entirely sure about this paragraph).

De data zijn van 1995. Misschien zijn er ondertussen al zaken maatschappelijk veranderd, waardoor de effecten vandaag de dag anders zijn. 30 jaar is een volledige generatie...

At last, the data are from 1995. Since then, the social and economic environment could have changed, implying that our estimated relationships would not hold today as crime rates, reporting practices,... have changed. Thus, these results should be carefully intepreted in today's context as the mechanisms most likely changed in comparison to when the data collection happened.  

Our regression analysis is thus valid  for a subset of communities with complete data, but should not be generalized to all U.S. communities.



# References

Becker GS (1968) Crime and Punishment: An Economic Approach. J Polit Econ 76: 169–217

# References dataset

U. S. Department of Commerce, Bureau of the Census, Census Of Population And Housing 
1990 United States: Summary Tape File 1a & 3a (Computer Files),

U.S. Department Of Commerce, Bureau Of The Census Producer, Washington, DC and 
Inter-university Consortium for Political and Social Research Ann Arbor, Michigan. 
(1992)

U.S. Department of Justice, Bureau of Justice Statistics, Law Enforcement Management 
And Administrative Statistics (Computer File) U.S. Department Of Commerce, Bureau Of 
The Census Producer, Washington, DC and Inter-university Consortium for Political and 
Social Research Ann Arbor, Michigan. (1992)

U.S. Department of Justice, Federal Bureau of Investigation, Crime in the United 
States (Computer File) (1995)

Redmond, M. A. and A. Baveja: A Data-Driven Software Tool for Enabling Cooperative 
Information Sharing Among Police Departments. European Journal of Operational Research 
141 (2002) 660-678.

Rousseeuw, P. J., & van Zomeren, B. C. (1990). Unmasking Multivariate Outliers and Leverage Points. Journal of the American Statistical Association, 85(411), 633–639. https://doi.org/10.1080/01621459.1990.10474920
